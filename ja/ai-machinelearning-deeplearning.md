---
title: "人工知能、機械学習、ディープラーニングの関係"
layout: ja-default
---


# 人工知能、機械学習、ディープラーニングの関係

ディープラーニングの機械学習や人工知能との関係は、最も小さい人形から大きなものへと、人形の内部や外部にも人形があるロシアの入れ子人形のようなものです。人工知能のサブセット（部分集合）である機械学習のサブセットがディープラーニングです。

人工知能とは、大まかに言うと、何か賢いことをするコンピュータプログラムです。

If-then文を重ねたものであることもあれば、複雑な統計モデルであることもあります。通常、人工知能研究者によって設計されたコンピュータプログラムが、例えばチェスに勝つなど何かに成功したら、多くの人は「本当に知的なわけではない」と言います。これは、人々がアルゴリズムの本質をよく理解しているからでしょう。ですから、真の人工知能とはコンピューターがまだできないことと言えるでしょう。(^_-)

先にも述べたように機械学習は人工知能のサブセットです。つまり、すべての機械学習は人工知能と言えますが、すべての人工知能が機械学習であるというわけではありません。例えば、記号論理（ルールエンジン、エキスパートシステム、ナレッジグラフ）や進化的アルゴリズム、ベイズ統計学などはどれも人工知能であると言えますが、機械学習とは言えません。

<p align="center">
<a href="quickstart" type="button" class="btn btn-lg btn-success" onClick="ga('send', 'event', equickstart', 'click');">DEEPLEARNING4Jを使ってみる</a>
</p>

機械学習でいう「学習」とは、機械学習アルゴリズムが特定の次元で最適化を試みる、という作業を指します。この試みは、一般にエラーを最小限にする、または推論が真である可能性を最大限にすることです。この作業を表すのに3つの名前が使われています。エラー関数、損失関数、またはアルゴリズムは目的を持っているということから、目的関数という名前もあります。機械学習アルゴリズムを使用していると言う人がいれば、目的関数とは何ですか、という質問をするとその価値が大体分かります。

どうやってエラーを最小限にするのでしょうか？一つの方法は、入力データの性質から推論を行うために入力データの乗算をするフレームワークを構築することです。出力データ／推論の結果が異なるのは、入力データやアルゴリズムが原因です。通常は、最初の推論はかなり間違っており、運よく入力データに関連した正解ラベルがあれば、推論を正解と照らし合わせて推論がどれほど間違っているかを測定し、エラーを使用してアルゴリズムを修正することができます。これがニューラルネットワークの行う作業です。最小限になるまでエラーの修正を続けるのです。

つまり簡単に言うと、ニューラルネットワークとは最適化アルゴリズムなのです。正しく調節すると、推論を何度も行い、エラーを最小限にします。

ディープラーニングは機械学習のサブセットです。ディープ人工ニューラルネットワークとは、画像認識、音声認識、レコメンダーシステムなど数多くの重要な問題に対する答えの精度の記録を更新するアルゴリズム一式なのです。ディープラーニングは、DeepMind社の評判の芳しくないAlphaGoアルゴリズムの一部ですが、2016年の初めに世界チャンピオンだった李世ドル氏に打ち勝ちました。ニューラルネットワークの完全ガイドは、[こちら](https://deeplearning4j.org/ja/neuralnet-overview)をお読みください。

ディープとは技術用語で、ニューラルネットワークに複数ある層を表したものです。浅いネットワークには、*隠れ層*と言うものが一つだけありますが、ディープ（深層）ネットワークには複数の層があります。複数の隠れ層によって、ディープ・ニューラル・ネットワークはデータの特徴を階層構造で学習します。シンプルな特徴（例えば2画素）がある層から次の層で再度組み合わされ、より複雑な特徴（例えば線）が形成されるのです。

### <a name="beginner">その他の Deeplearning4jのチュートリアル</a>
* [ディープニューラルネットワークについて](https://deeplearning4j.org/ja/neuralnet-overview)
* [Word2Vecとは？](https://deeplearning4j.org/ja/word2vec)
* [制限付きボルツマンマシンの初心者向けガイド](https://deeplearning4j.org/ja/restrictedboltzmannmachine)
* [固有ベクトル、主成分分析、共分散、エントロピー入門](https://deeplearning4j.org/ja/eigenvector)
* [再帰型ネットワークと長・短期記憶についての初心者ガイド](https://deeplearning4j.org/ja/lstm)
* [回帰を使ったニューラルネットワーク](https://deeplearning4j.org/ja/linear-regression)
* [畳み込みネットワーク](https://deeplearning4j.org/ja/convolutionalnets)
