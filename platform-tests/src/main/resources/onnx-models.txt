vision/body_analysis/age_gender/models/gender_googlenet.onnx
vision/body_analysis/age_gender/models/vgg_ilsvrc_16_age_chalearn_iccv2015.onnx
vision/body_analysis/age_gender/models/vgg_ilsvrc_16_age_imdb_wiki.onnx
vision/body_analysis/age_gender/models/vgg_ilsvrc_16_gender_imdb_wiki.onnx
vision/body_analysis/arcface/model/arcfaceresnet100-8.onnx
vision/body_analysis/emotion_ferplus/model/emotion-ferplus-2.onnx
vision/body_analysis/emotion_ferplus/model/emotion-ferplus-7.onnx
vision/body_analysis/emotion_ferplus/model/emotion-ferplus-8.onnx
vision/body_analysis/ultraface/models/version-RFB-320.onnx
vision/classification/alexnet/model/bvlcalexnet-9.onnx
vision/classification/caffenet/model/caffenet-9.onnx
vision/classification/densenet-121/model/densenet-9.onnx
vision/classification/efficientnet-lite4/model/efficientnet-lite4-11.onnx
vision/classification/inception_and_googlenet/googlenet/model/googlenet-9.onnx
vision/classification/inception_and_googlenet/inception_v2/model/inception-v2-9.onnx
vision/classification/mnist/model/mnist-8.onnx
vision/classification/rcnn_ilsvrc13/model/rcnn-ilsvrc13-9.onnx
vision/classification/resnet/model/resnet101-v1-7.onnx
vision/classification/resnet/model/resnet152-v2-7.onnx
vision/classification/resnet/model/resnet18-v1-7.onnx
vision/classification/resnet/model/resnet18-v2-7.onnx
vision/classification/resnet/model/resnet34-v1-7.onnx
vision/classification/resnet/model/resnet34-v2-7.onnx
vision/classification/shufflenet/model/shufflenet-9.onnx
vision/classification/shufflenet/model/shufflenet-v2-10.onnx
vision/classification/squeezenet/model/squeezenet1.0-9.onnx
vision/classification/squeezenet/model/squeezenet1.1-7.onnx
vision/classification/vgg/model/vgg16-7.onnx
vision/classification/vgg/model/vgg16-bn-7.onnx
vision/classification/vgg/model/vgg19-7.onnx
vision/classification/vgg/model/vgg19-caffe2-9.onnx
vision/classification/zfnet-512/model/zfnet512-9.onnx
vision/object_detection_segmentation/duc/model/ResNet101-DUC-7.onnx
vision/object_detection_segmentation/faster-rcnn/model/FasterRCNN-10.onnx
vision/object_detection_segmentation/fcn/model/fcn-resnet101-11.onnx
vision/object_detection_segmentation/fcn/model/fcn-resnet50-11.onnx
vision/object_detection_segmentation/mask-rcnn/model/MaskRCNN-10.onnx
vision/object_detection_segmentation/retinanet/model/retinanet-9.onnx
vision/object_detection_segmentation/ssd-mobilenetv1/model/ssd_mobilenet_v1_10.onnx
vision/object_detection_segmentation/ssd/model/ssd-10.onnx
vision/object_detection_segmentation/tiny-yolov2/model/tinyyolov2-7.onnx
vision/object_detection_segmentation/tiny-yolov2/model/tinyyolov2-8.onnx
vision/object_detection_segmentation/tiny-yolov3/model/tiny-yolov3-11.onnx
vision/object_detection_segmentation/yolov2-coco/model/yolov2-coco-9.onnx
vision/object_detection_segmentation/yolov3/model/yolov3-10.onnx
vision/object_detection_segmentation/yolov4/model/yolov4.onnx
vision/style_transfer/fast_neural_style/model/candy-8.onnx
vision/style_transfer/fast_neural_style/model/candy-9.onnx
/vision/style_transfer/fast_neural_style/model/mosaic-8.onnx
vision/style_transfer/fast_neural_style/model/mosaic-9.onnx
vision/style_transfer/fast_neural_style/model/pointilism-8.onnx
vision/style_transfer/fast_neural_style/model/pointilism-9.onnx
vision/style_transfer/fast_neural_style/model/rain-princess-8.onnx
vision/style_transfer/fast_neural_style/model/rain-princess-9.onnx
vision/style_transfer/fast_neural_style/model/udnie-8.onnx
vision/style_transfer/fast_neural_style/model/udnie-9.onnx
vision/super_resolution/sub_pixel_cnn_2016/model/super-resolution-10.onnx
text/machine_comprehension/bert-squad/model/bertsquad-10.onnx
text/machine_comprehension/bert-squad/model/bertsquad-8.onnx
text/machine_comprehension/bidirectional_attention_flow/model/bidaf-9.onnx
text/machine_comprehension/gpt-2/model/gpt2-10.onnx
text/machine_comprehension/gpt-2/model/gpt2-lm-head-10.onnx
text/machine_comprehension/roberta/model/roberta-base-11.onnx
text/machine_comprehension/roberta/model/roberta-sequence-classification-9.onnx
text/machine_comprehension/t5/model/t5-decoder-with-lm-head-12.onnx
text/machine_comprehension/t5/model/t5-encoder-12.onnx