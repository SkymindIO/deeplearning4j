---
title: 分词
layout: cn-default
---
<p><h1>分词</h1></p>
<p>分词（tokenization）是将文本分解为单个词语的过程。词窗口也是由词例（token）组成的。<a href="word2vec">Word2Vec</a>可以输出文本窗口，作为定型样例输入神经网络，如下文所示。</p>
<p>以下是用DL4J工具进行分词的示例：</p>
<pre class="line-numbers"><code class="language-java">
//采用词形还原、词性标注、语句切分的分词 
	TokenizerFactory tokenizerFactory = new UimaTokenizerFactory(); Tokenizer tokenizer = tokenizerFactory.tokenize(“mystring”);

	//对词例进行迭代
    while(tokenizer.hasMoreTokens()) {
      	   String token = tokenizer.nextToken();
    }
      
    //获得整个词例列表
    List&lt;String&gt; tokens = tokenizer.getTokens();
</code></pre>
<p>上述代码创建了能够进行词干提取的分词器。</p>
<p>我们推荐在Word2Vec中采用这种方式生成词汇表，如此可以避免词汇表出现异常，比如同一个名词的单数和复数形式被记为两个不同的词。</p>
