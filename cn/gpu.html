---
title: 用GPU运行Deeplearning4j
layout: cn-default
---
<h1>用GPU运行Deeplearning4j</h1>
<p>Deeplearning4j同时支持分布式和本机GPU。用户可以用NVIDIA Tesla、Titan、GeForce GTX等单个本地GPU运行DL4J，也可以使用云端的NVIDIA GRID GPU来运行。</p>
<p>若要在GPU上训练神经网络，您需要对根目录下的POM.xml文件做一项更改。<a href="quickstart" target="_blank">快速入门指南</a>中提到了一个默认状态下将项目配置成在CPU上运行的POM文件。具体配置内容如下：</p>
<pre class="line-numbers"><code class="language-java">
&lt;name&gt;DeepLearning4j Examples Parent&lt;/name&gt;
        &lt;description&gt;Examples of training different data sets&lt;/description&gt;
        &lt;properties&gt;
            &lt;nd4j.backend&gt;nd4j-native-platform&lt;/nd4j.backend&gt;
</code></pre>
<br>
<p>将最后一行改为如下形式即可：</p>
<pre><code class="language-java">
&lt;nd4j.backend>nd4j-cuda-8.0-platform/&lt;nd4j.backend&gt;
</code></pre>
<br>
<p>ND4J是驱动Deeplearning4j的数值运算引擎。它依靠各种&ldquo;后端&rdquo;在不同类型的硬件上运行。<a href="https://gitter.im/deeplearning4j/deeplearning4j">Deeplearning4j线上交流群</a>的用户常会提到后端，他们说的就是指向某种芯片的软件包。我们在后端上开展硬件优化工作。</p>
<br>
<br>
<h3>疑难解答</h3>
<p>如果您有多个GPU，但系统却只允许使用一个，解决方法如下：将<code>CudaEnvironment.getInstance().getConfiguration().allowMultiGPU(true);</code>添加至<code>main()</code>方法的第一行即可。</p>
<br>
<br>
<h3>多GPU数据并行模式</h3>
<p>如果您的系统安装有多个GPU，就可以用数据并行模式来训练模型。我们有一个实现数据并行的简单的包装类。您可以考虑以下的用法：</p>
<pre class="line-numbers"><code class="language-java">
ParallelWrapper wrapper = new ParallelWrapper.Builder(YourExistingModel)
        .prefetchBuffer(24)
        .workers(4)
        .averagingFrequency(1)
        .reportScoreAfterAveraging(true)
        .useLegacyAveraging(false)
        .build();
</code></pre>
<p><code>ParallelWrapper</code>（并行包装类）将您的现有模型作为主要参数，以并行模式进行训练。若使用GPU，我们建议确保工作器数量等于或高于GPU的数量。具体数值需要进行调试，因为它们取决于具体的任务以及可用的硬件。</p>
<p><code>ParallelWrapper</code>会复制您的初始模型，每个工作器分别训练自己的模型。每进行<em>X</em>次迭代后（该迭代次数由<code>averagingFrequency(X)</code>设置），所有模型将被平均化，然后继续训练。</p>
<p>需要提醒的是，我们建议数据并行模式的训练采用更高的学习速率。初始速率应当可以提高20%左右。</p>
<br>
<br>
<h3>采用并行包装类的早停法</h3>
<p>专用早停类<code>EarlyStoppingParallelTrainer</code>可以实现与单GPU设备上的早停法相似的功能。更多有关早停法的内容参见<a href="earlystopping">此处</a>。</p>
<br>
<br>
<h3>HALF数据类型</h3>
<p>如果您的应用程序有条件使用半精度浮点数（神经网络一般都能支持），启用这一数据类型可以带来以下好处：</p>
<ul>
  <li>GPU RAM使用量减少一半</li>
  <li>存占用量大的运算的性能最高可以提升200%，不过实际的性能提升幅度取决于具体的任务和所用硬件。<br>
  <pre class="line-numbers"><code class="language-java">
  DataTypeUtil.setDTypeForContext(DataBuffer.Type.HALF);
  </code></pre></li>
</ul>
<br>
<br>
<p>将这一条调用命令置于应用程序代码的首行，让所有后续的分配/计算以HALF数据类型进行。</p>
<p>但是应当注意：HALF数据类型的精确率远小于FLOAT和DOUBLE类型，因此神经网络调试的难度可能也会大幅上升。</p>
<p>此外，目前我们暂时不能为HALF数据类型提供完全的LAPACK支持。</p>
<br>
<br>
<h2>扩大网格</h2>
<p>默认设定值适用于大多数GPU，但如果您使用的是高端硬件，且数据量足够庞大，那么或许可以尝试提高网格/块的上限。比如可以采用如下方法：</p>
<pre class="line-numbers"><code class="language-java">
CudaEnvironment.getInstance().getConfiguration()
      .setMaximumGridSize(512)
      .setMaximumBlockSize(512);
</code></pre>
<p>这不会迫使所有的运算（甚至是次要的运算）都使用特定的网格尺寸，但会为其设定理论限制。</p>
<br>
<br>
<h2>扩大缓存</h2>
<p>ND4J基于Java，因此缓存大小对于CUDA后端非常重要，有可能大幅提升或降低性能表现。如果您的RAM容量足够大，直接扩大缓存容量即可。</p>
<p>比如可以采用如下方法：</p>
<pre class="line-numbers"><code class="language-java">
CudaEnvironment.getInstance().getConfiguration()
    .setMaximumDeviceCacheableLength(1024 * 1024 * 1024L)
    .setMaximumDeviceCache(6L * 1024 * 1024 * 1024L)
    .setMaximumHostCacheableLength(1024 * 1024 * 1024L)
    .setMaximumHostCache(6L * 1024 * 1024 * 1024L);
</code></pre>
<br>
<p>上述代码将允许最多把6GB的GPU RAM用作缓存（实际并不一定会分配这么多），而主机和GPU内存的每个已缓存内存块最大可达1GB。</p>
<p>由于ND4J的缓存采用一项&ldquo;再利用&rdquo;范式，这些较高的设置值不会造成任何负面影响。只有分配给您的应用程序的内存块才能缓存以供再利用。</p>
<br>
<br>
<h2>设置环境变量BACKEND_PRIORITY_CPU和BACKEND_PRIORITY_GPU</h2>
<p>环境变量BACKEND_PRIORITY_CPU和BACKEND_PRIORITY_GPU的设置可以决定采用的是GPU还是CPU后端。具体用法是将BACKEND_PRIORITY_CPU和BACKEND_PRIORITY_GPU设置为整数。最高的值对应的后端将被采用。</p>
<br>
<br>
<h2>具体运作方式</h2>
<p>由于GPU和x86之间的区别，CUDA后端与本机后端相比存在一些设计上的差异。</p>
<p>相关要点如下：</p>
<ul>
  <li>CUDA后端高度依赖各类内存缓存。
    <ul>
      <li>每个内存块被分配一次，从JVM上下文释放后，我们将其缓存以供之后再次利用。</li>
      <li>ShapeInfo和TAD缓存用GPU设备的常量内存提高从内核（kernel）上下文访问的速度。</li>
    </ul>
  </li>
  <li>内核是&ldquo;原子性&rdquo;的（atomic，即不可分割）：一项运算 = 一个预编译的内核（多数情况下均是如此）</li>
  <li>CUDA后端会在实际内核启动之前处理并行配置</li>
  <li>有些情况下，我们可以在一次运算调用中进行2项运算。这种执行模式称为mGRID，有利于PairwiseTransform运算及之后的其他运算。</li>
  <li>与nd4j-native后端相似，CUDA后端支持两种并行模式：    * 元素层级的并行：网格中的所有线程均使用同一个线性缓冲区。    * TAD层级的并行：网格被划分为多个块，每个线程块处理一个TAD。</li>
  <li>设备内存释放进程由WeakReferences处理（随后是上文提到的缓存机制）</li>
  <li>多GPU环境实行线程 &lt;-&gt; 设备关联管理。一个Java线程在任何时候都与一个GPU相关联。</li>
</ul>
<br>
<br>
<h2>扩展阅读</h2>
<ul>
  <li><a href="spark">基于Spark的Deeplearning4j（采用GPU）</a></li>
  <li><a href="native">用OpenMP和SIMD指令对Deeplearning4j进行本机优化</a></li>
</ul>
<p>&nbsp;</p>
