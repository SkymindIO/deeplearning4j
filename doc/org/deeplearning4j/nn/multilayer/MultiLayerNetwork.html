<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_111) on Thu Mar 30 11:58:00 PDT 2017 -->
<title>MultiLayerNetwork</title>
<meta name="date" content="2017-03-30">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="MultiLayerNetwork";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":10,"i1":10,"i2":10,"i3":10,"i4":10,"i5":10,"i6":10,"i7":10,"i8":10,"i9":10,"i10":10,"i11":10,"i12":10,"i13":10,"i14":10,"i15":10,"i16":10,"i17":10,"i18":10,"i19":10,"i20":10,"i21":10,"i22":10,"i23":10,"i24":10,"i25":10,"i26":10,"i27":10,"i28":10,"i29":10,"i30":10,"i31":10,"i32":10,"i33":10,"i34":10,"i35":10,"i36":10,"i37":10,"i38":10,"i39":10,"i40":10,"i41":10,"i42":10,"i43":10,"i44":10,"i45":10,"i46":10,"i47":10,"i48":10,"i49":10,"i50":10,"i51":10,"i52":10,"i53":10,"i54":10,"i55":10,"i56":10,"i57":10,"i58":10,"i59":10,"i60":10,"i61":10,"i62":10,"i63":10,"i64":10,"i65":10,"i66":10,"i67":10,"i68":10,"i69":10,"i70":10,"i71":10,"i72":10,"i73":10,"i74":10,"i75":10,"i76":10,"i77":10,"i78":10,"i79":10,"i80":10,"i81":10,"i82":10,"i83":10,"i84":10,"i85":10,"i86":10,"i87":10,"i88":10,"i89":42,"i90":42,"i91":10,"i92":10,"i93":10,"i94":10,"i95":10,"i96":10,"i97":10,"i98":10,"i99":10,"i100":10,"i101":10,"i102":10,"i103":10,"i104":10,"i105":10,"i106":10,"i107":10,"i108":10,"i109":10,"i110":42,"i111":10,"i112":10,"i113":10,"i114":10,"i115":10,"i116":10,"i117":10,"i118":10,"i119":10,"i120":10,"i121":10,"i122":10,"i123":10,"i124":10,"i125":10,"i126":10,"i127":10,"i128":10,"i129":10,"i130":10,"i131":10,"i132":10,"i133":10,"i134":10,"i135":10,"i136":10,"i137":10,"i138":10,"i139":10,"i140":10,"i141":10,"i142":10,"i143":10,"i144":10,"i145":10,"i146":10,"i147":10,"i148":10,"i149":10,"i150":10,"i151":10,"i152":10,"i153":10,"i154":10};
var tabs = {65535:["t0","All Methods"],2:["t2","Instance Methods"],8:["t4","Concrete Methods"],32:["t6","Deprecated Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/deeplearning4j/nn/multilayer/GravesLSTMOutputTest.html" title="class in org.deeplearning4j.nn.multilayer"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerTest.html" title="class in org.deeplearning4j.nn.multilayer"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" target="_top">Frames</a></li>
<li><a href="MultiLayerNetwork.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field.summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field.detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.deeplearning4j.nn.multilayer</div>
<h2 title="Class MultiLayerNetwork" class="title">Class MultiLayerNetwork</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li>org.deeplearning4j.nn.multilayer.MultiLayerNetwork</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, java.lang.Cloneable, <a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a>, <a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>, <a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="typeNameLabel">MultiLayerNetwork</span>
extends java.lang.Object
implements java.io.Serializable, <a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a>, <a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></pre>
<div class="block">MultiLayerNetwork is a neural network with multiple layers in a stack, and usually an output layer.
 For neural networks with a more complex connection architecture, use <a href="../../../../org/deeplearning4j/nn/graph/ComputationGraph.html" title="class in org.deeplearning4j.nn.graph"><code>ComputationGraph</code></a>
 which allows for an arbitrary directed acyclic graph connection structure between layers.
 MultiLayerNetwork is trainable via backprop, with optional pretraining, depending on the type of layers it contains.</div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../serialized-form.html#org.deeplearning4j.nn.multilayer.MultiLayerNetwork">Serialized Form</a></dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested.class.summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<ul class="blockList">
<li class="blockList"><a name="nested.classes.inherited.from.class.org.deeplearning4j.nn.api.Layer">
<!--   -->
</a>
<h3>Nested classes/interfaces inherited from interface&nbsp;org.deeplearning4j.nn.api.<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></h3>
<code><a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>, <a href="../../../../org/deeplearning4j/nn/api/Layer.Type.html" title="enum in org.deeplearning4j.nn.api">Layer.Type</a></code></li>
</ul>
</li>
</ul>
<!-- =========== FIELD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="field.summary">
<!--   -->
</a>
<h3>Field Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Field Summary table, listing fields, and an explanation">
<caption><span>Fields</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Field and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#defaultConfiguration">defaultConfiguration</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#epsilon">epsilon</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#flattenedGradients">flattenedGradients</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#flattenedParams">flattenedParams</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#gradient">gradient</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#initCalled">initCalled</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#initDone">initDone</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#input">input</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#labels">labels</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#layerIndex">layerIndex</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected java.util.LinkedHashMap&lt;java.lang.String,<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#layerMap">layerMap</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#layers">layers</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#layerWiseConfigurations">layerWiseConfigurations</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#mask">mask</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score">score</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/deeplearning4j/optimize/Solver.html" title="class in org.deeplearning4j.optimize">Solver</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#solver">solver</a></span></code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#MultiLayerNetwork-org.deeplearning4j.nn.conf.MultiLayerConfiguration-">MultiLayerNetwork</a></span>(<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;conf)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#MultiLayerNetwork-org.deeplearning4j.nn.conf.MultiLayerConfiguration-org.nd4j.linalg.api.ndarray.INDArray-">MultiLayerNetwork</a></span>(<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;conf,
                 org.nd4j.linalg.api.ndarray.INDArray&nbsp;params)</code>
<div class="block">Initialize the network based on the configuraiton</div>
</td>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#MultiLayerNetwork-java.lang.String-org.nd4j.linalg.api.ndarray.INDArray-">MultiLayerNetwork</a></span>(java.lang.String&nbsp;conf,
                 org.nd4j.linalg.api.ndarray.INDArray&nbsp;params)</code>
<div class="block">Initialize the network based on the configuration</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">Instance Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t6" class="tableTab"><span><a href="javascript:show(32);">Deprecated Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#accumulateScore-double-">accumulateScore</a></span>(double&nbsp;accum)</code>
<div class="block">Sets a rolling tally for the score.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate--">activate</a></span>()</code>
<div class="block">Triggers the activation of the last hidden layer ie: not logistic regression</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate-boolean-">activate</a></span>(boolean&nbsp;training)</code>
<div class="block">Trigger an activation with the last specified input</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate-org.nd4j.linalg.api.ndarray.INDArray-">activate</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</code>
<div class="block">Initialize the layer with the given input
 and return the activation for this layer
 given this input</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate-org.nd4j.linalg.api.ndarray.INDArray-boolean-">activate</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
        boolean&nbsp;training)</code>
<div class="block">Initialize the layer with the given input
 and return the activation for this layer
 given this input</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">activate</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
        <a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</code>
<div class="block">Initialize the layer with the given input
 and return the activation for this layer
 given this input</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate-int-">activate</a></span>(int&nbsp;layer)</code>
<div class="block">Triggers the activation for a given layer</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate-int-org.nd4j.linalg.api.ndarray.INDArray-">activate</a></span>(int&nbsp;layer,
        org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</code>
<div class="block">Triggers the activation of the given layer</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate-org.deeplearning4j.nn.api.Layer.TrainingMode-">activate</a></span>(<a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</code>
<div class="block">Trigger an activation with the last specified input</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activateSelectedLayers-int-int-org.nd4j.linalg.api.ndarray.INDArray-">activateSelectedLayers</a></span>(int&nbsp;from,
                      int&nbsp;to,
                      org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</code>
<div class="block">Calculate activation for few layers at once.</div>
</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activationFromPrevLayer-int-org.nd4j.linalg.api.ndarray.INDArray-boolean-">activationFromPrevLayer</a></span>(int&nbsp;curr,
                       org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
                       boolean&nbsp;training)</code>
<div class="block">Calculate activation from previous layer including pre processing where necessary</div>
</td>
</tr>
<tr id="i11" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activationMean--">activationMean</a></span>()</code>
<div class="block">Calculate the mean representation
 for the activation for this layer</div>
</td>
</tr>
<tr id="i12" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#applyLearningRateScoreDecay--">applyLearningRateScoreDecay</a></span>()</code>
<div class="block">Update learningRate using for this model.</div>
</td>
</tr>
<tr id="i13" class="rowColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#backprop--">backprop</a></span>()</code>
<div class="block">Calculate and set gradients for MultiLayerNetwork, based on OutputLayer and labels</div>
</td>
</tr>
<tr id="i14" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#backpropGradient-org.nd4j.linalg.api.ndarray.INDArray-">backpropGradient</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;epsilon)</code>
<div class="block">Calculate the gradient relative to the error in the next layer</div>
</td>
</tr>
<tr id="i15" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#batchSize--">batchSize</a></span>()</code>
<div class="block">The current inputs batch size</div>
</td>
</tr>
<tr id="i16" class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#calcBackpropGradients-org.nd4j.linalg.api.ndarray.INDArray-boolean-">calcBackpropGradients</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;epsilon,
                     boolean&nbsp;withOutputLayer)</code>
<div class="block">Calculate gradients and errors.</div>
</td>
</tr>
<tr id="i17" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#calcGradient-org.deeplearning4j.nn.gradient.Gradient-org.nd4j.linalg.api.ndarray.INDArray-">calcGradient</a></span>(<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;layerError,
            org.nd4j.linalg.api.ndarray.INDArray&nbsp;activation)</code>
<div class="block">Calculate the gradient</div>
</td>
</tr>
<tr id="i18" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#calcL1-boolean-">calcL1</a></span>(boolean&nbsp;backpropParamsOnly)</code>
<div class="block">Calculate the l1 regularization term<br>
 0.0 if regularization is not used.</div>
</td>
</tr>
<tr id="i19" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#calcL2-boolean-">calcL2</a></span>(boolean&nbsp;backpropParamsOnly)</code>
<div class="block">Calculate the l2 regularization term<br>
 0.0 if regularization is not used.</div>
</td>
</tr>
<tr id="i20" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#clear--">clear</a></span>()</code>
<div class="block">Clear the inputs.</div>
</td>
</tr>
<tr id="i21" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#clearLayerMaskArrays--">clearLayerMaskArrays</a></span>()</code>
<div class="block">Remove the mask arrays from all layers.<br>
 See <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLayerMaskArrays-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-"><code>setLayerMaskArrays(INDArray, INDArray)</code></a> for details on mask arrays.</div>
</td>
</tr>
<tr id="i22" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" title="class in org.deeplearning4j.nn.multilayer">MultiLayerNetwork</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#clone--">clone</a></span>()</code>
<div class="block">Clone the layer</div>
</td>
</tr>
<tr id="i23" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#computeGradientAndScore--">computeGradientAndScore</a></span>()</code>
<div class="block">Update the score</div>
</td>
</tr>
<tr id="i24" class="altColor">
<td class="colFirst"><code>java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#computeZ-boolean-">computeZ</a></span>(boolean&nbsp;training)</code>
<div class="block">* Compute input linear transformation (z) of the output layer</div>
</td>
</tr>
<tr id="i25" class="rowColor">
<td class="colFirst"><code>java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#computeZ-org.nd4j.linalg.api.ndarray.INDArray-boolean-">computeZ</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
        boolean&nbsp;training)</code>
<div class="block">Compute activations from input to output of the output layer</div>
</td>
</tr>
<tr id="i26" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#conf--">conf</a></span>()</code>
<div class="block">The configuration for the neural network</div>
</td>
</tr>
<tr id="i27" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#derivativeActivation-org.nd4j.linalg.api.ndarray.INDArray-">derivativeActivation</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</code>
<div class="block">Take the derivative of the given input
 based on the activation</div>
</td>
</tr>
<tr id="i28" class="altColor">
<td class="colFirst"><code>&lt;T extends <a href="../../../../org/deeplearning4j/eval/IEvaluation.html" title="interface in org.deeplearning4j.eval">IEvaluation</a>&gt;<br>T</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#doEvaluation-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-T-">doEvaluation</a></span>(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator,
            T&nbsp;evaluation)</code>
<div class="block">Perform evaluation using an arbitrary IEvaluation instance.</div>
</td>
</tr>
<tr id="i29" class="rowColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#doTruncatedBPTT-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">doTruncatedBPTT</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
               org.nd4j.linalg.api.ndarray.INDArray&nbsp;labels,
               org.nd4j.linalg.api.ndarray.INDArray&nbsp;featuresMaskArray,
               org.nd4j.linalg.api.ndarray.INDArray&nbsp;labelsMaskArray)</code>&nbsp;</td>
</tr>
<tr id="i30" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#epsilon--">epsilon</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i31" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#error-org.nd4j.linalg.api.ndarray.INDArray-">error</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;errorSignal)</code>
<div class="block">Calculate error with respect to the
 current layer.</div>
</td>
</tr>
<tr id="i32" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/eval/Evaluation.html" title="class in org.deeplearning4j.eval">Evaluation</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#evaluate-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">evaluate</a></span>(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator)</code>
<div class="block">Evaluate the network (classification performance)</div>
</td>
</tr>
<tr id="i33" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/eval/Evaluation.html" title="class in org.deeplearning4j.eval">Evaluation</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#evaluate-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-java.util.List-">evaluate</a></span>(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator,
        java.util.List&lt;java.lang.String&gt;&nbsp;labelsList)</code>
<div class="block">Evaluate the network on the provided data set.</div>
</td>
</tr>
<tr id="i34" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/eval/Evaluation.html" title="class in org.deeplearning4j.eval">Evaluation</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#evaluate-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-java.util.List-int-">evaluate</a></span>(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator,
        java.util.List&lt;java.lang.String&gt;&nbsp;labelsList,
        int&nbsp;topN)</code>
<div class="block">Evaluate the network (for classification) on the provided data set, with top N accuracy in addition to standard accuracy.</div>
</td>
</tr>
<tr id="i35" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/eval/RegressionEvaluation.html" title="class in org.deeplearning4j.eval">RegressionEvaluation</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#evaluateRegression-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">evaluateRegression</a></span>(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator)</code>
<div class="block">Evaluate the network for regression performance</div>
</td>
</tr>
<tr id="i36" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/eval/ROC.html" title="class in org.deeplearning4j.eval">ROC</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#evaluateROC-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-int-">evaluateROC</a></span>(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator,
           int&nbsp;rocThresholdSteps)</code>
<div class="block">Evaluate the network (must be a binary classifier) on the specified data, using the <a href="../../../../org/deeplearning4j/eval/ROC.html" title="class in org.deeplearning4j.eval"><code>ROC</code></a> class</div>
</td>
</tr>
<tr id="i37" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/eval/ROCMultiClass.html" title="class in org.deeplearning4j.eval">ROCMultiClass</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#evaluateROCMultiClass-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-int-">evaluateROCMultiClass</a></span>(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator,
                     int&nbsp;rocThresholdSteps)</code>
<div class="block">Evaluate the network on the specified data, using the <a href="../../../../org/deeplearning4j/eval/ROCMultiClass.html" title="class in org.deeplearning4j.eval"><code>ROCMultiClass</code></a> class</div>
</td>
</tr>
<tr id="i38" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#f1Score-org.nd4j.linalg.dataset.api.DataSet-">f1Score</a></span>(org.nd4j.linalg.dataset.api.DataSet&nbsp;data)</code>
<div class="block">Sets the input and labels and returns a score for the prediction
 wrt true labels</div>
</td>
</tr>
<tr id="i39" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#f1Score-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">f1Score</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
       org.nd4j.linalg.api.ndarray.INDArray&nbsp;labels)</code>
<div class="block">Sets the input and labels and returns a score for the prediction
 wrt true labels</div>
</td>
</tr>
<tr id="i40" class="altColor">
<td class="colFirst"><code>java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForward--">feedForward</a></span>()</code>
<div class="block">Compute activations from input to output of the output layer</div>
</td>
</tr>
<tr id="i41" class="rowColor">
<td class="colFirst"><code>java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForward-boolean-">feedForward</a></span>(boolean&nbsp;train)</code>
<div class="block">Compute activations from input to output of the output layer</div>
</td>
</tr>
<tr id="i42" class="altColor">
<td class="colFirst"><code>java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForward-org.nd4j.linalg.api.ndarray.INDArray-">feedForward</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</code>
<div class="block">Compute activations from input to output of the output layer</div>
</td>
</tr>
<tr id="i43" class="rowColor">
<td class="colFirst"><code>java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForward-org.nd4j.linalg.api.ndarray.INDArray-boolean-">feedForward</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
           boolean&nbsp;train)</code>
<div class="block">Compute activations from input to output of the output layer</div>
</td>
</tr>
<tr id="i44" class="altColor">
<td class="colFirst"><code>java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForward-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">feedForward</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
           org.nd4j.linalg.api.ndarray.INDArray&nbsp;featuresMask,
           org.nd4j.linalg.api.ndarray.INDArray&nbsp;labelsMask)</code>
<div class="block">Compute the activations from the input to the output layer, given mask arrays (that may be null)
 The masking arrays are used in situations such an one-to-many and many-to-one rucerrent neural network (RNN)
 designs, as well as for supporting time series of varying lengths within the same minibatch for RNNs.</div>
</td>
</tr>
<tr id="i45" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;org.nd4j.linalg.api.ndarray.INDArray,<a href="../../../../org/deeplearning4j/nn/api/MaskState.html" title="enum in org.deeplearning4j.nn.api">MaskState</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForwardMaskArray-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.MaskState-int-">feedForwardMaskArray</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;maskArray,
                    <a href="../../../../org/deeplearning4j/nn/api/MaskState.html" title="enum in org.deeplearning4j.nn.api">MaskState</a>&nbsp;currentMaskState,
                    int&nbsp;minibatchSize)</code>
<div class="block">Feed forward the input mask array, setting in in the layer as appropriate.</div>
</td>
</tr>
<tr id="i46" class="altColor">
<td class="colFirst"><code>java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForwardToLayer-int-boolean-">feedForwardToLayer</a></span>(int&nbsp;layerNum,
                  boolean&nbsp;train)</code>
<div class="block">Compute the activations from the input to the specified layer, using the currently set input for the network.<br>
 To compute activations for all layers, use feedForward(...) methods<br>
 Note: output list includes the original input.</div>
</td>
</tr>
<tr id="i47" class="rowColor">
<td class="colFirst"><code>java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForwardToLayer-int-org.nd4j.linalg.api.ndarray.INDArray-">feedForwardToLayer</a></span>(int&nbsp;layerNum,
                  org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</code>
<div class="block">Compute the activations from the input to the specified layer.<br>
 To compute activations for all layers, use feedForward(...) methods<br>
 Note: output list includes the original input.</div>
</td>
</tr>
<tr id="i48" class="altColor">
<td class="colFirst"><code>java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForwardToLayer-int-org.nd4j.linalg.api.ndarray.INDArray-boolean-">feedForwardToLayer</a></span>(int&nbsp;layerNum,
                  org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
                  boolean&nbsp;train)</code>
<div class="block">Compute the activations from the input to the specified layer.<br>
 To compute activations for all layers, use feedForward(...) methods<br>
 Note: output list includes the original input.</div>
</td>
</tr>
<tr id="i49" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#finetune--">finetune</a></span>()</code>
<div class="block">Run SGD based on the given labels</div>
</td>
</tr>
<tr id="i50" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit--">fit</a></span>()</code>
<div class="block">All models have a fit method</div>
</td>
</tr>
<tr id="i51" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit-org.nd4j.linalg.dataset.api.DataSet-">fit</a></span>(org.nd4j.linalg.dataset.api.DataSet&nbsp;data)</code>
<div class="block">Fit the model</div>
</td>
</tr>
<tr id="i52" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">fit</a></span>(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator)</code>
<div class="block">Train the model based on the datasetiterator</div>
</td>
</tr>
<tr id="i53" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit-org.nd4j.linalg.api.ndarray.INDArray-">fit</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;data)</code>
<div class="block">Fit the unsupervised model</div>
</td>
</tr>
<tr id="i54" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">fit</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;data,
   org.nd4j.linalg.api.ndarray.INDArray&nbsp;labels)</code>
<div class="block">Fit the model</div>
</td>
</tr>
<tr id="i55" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">fit</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;features,
   org.nd4j.linalg.api.ndarray.INDArray&nbsp;labels,
   org.nd4j.linalg.api.ndarray.INDArray&nbsp;featuresMask,
   org.nd4j.linalg.api.ndarray.INDArray&nbsp;labelsMask)</code>
<div class="block">Fit the model</div>
</td>
</tr>
<tr id="i56" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit-org.nd4j.linalg.api.ndarray.INDArray-int:A-">fit</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;examples,
   int[]&nbsp;labels)</code>
<div class="block">Fit the model</div>
</td>
</tr>
<tr id="i57" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getDefaultConfiguration--">getDefaultConfiguration</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i58" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getIndex--">getIndex</a></span>()</code>
<div class="block">Get the layer index.</div>
</td>
</tr>
<tr id="i59" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getInput--">getInput</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i60" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getInputMiniBatchSize--">getInputMiniBatchSize</a></span>()</code>
<div class="block">Get current/last input mini-batch size, as set by setInputMiniBatchSize(int)</div>
</td>
</tr>
<tr id="i61" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLabels--">getLabels</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i62" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLayer-int-">getLayer</a></span>(int&nbsp;i)</code>&nbsp;</td>
</tr>
<tr id="i63" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLayer-java.lang.String-">getLayer</a></span>(java.lang.String&nbsp;name)</code>&nbsp;</td>
</tr>
<tr id="i64" class="altColor">
<td class="colFirst"><code>java.util.List&lt;java.lang.String&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLayerNames--">getLayerNames</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i65" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLayers--">getLayers</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i66" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLayerWiseConfigurations--">getLayerWiseConfigurations</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i67" class="rowColor">
<td class="colFirst"><code>java.util.Collection&lt;<a href="../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getListeners--">getListeners</a></span>()</code>
<div class="block">Get the iteration listeners for this layer.</div>
</td>
</tr>
<tr id="i68" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getMask--">getMask</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i69" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getMaskArray--">getMaskArray</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i70" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getnLayers--">getnLayers</a></span>()</code>
<div class="block">Get the number of layers in the network</div>
</td>
</tr>
<tr id="i71" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/optimize/api/ConvexOptimizer.html" title="interface in org.deeplearning4j.optimize.api">ConvexOptimizer</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getOptimizer--">getOptimizer</a></span>()</code>
<div class="block">Returns this models optimizer</div>
</td>
</tr>
<tr id="i72" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getOutputLayer--">getOutputLayer</a></span>()</code>
<div class="block">Get the output layer</div>
</td>
</tr>
<tr id="i73" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getParam-java.lang.String-">getParam</a></span>(java.lang.String&nbsp;param)</code>
<div class="block">Get the parameter</div>
</td>
</tr>
<tr id="i74" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Updater.html" title="interface in org.deeplearning4j.nn.api">Updater</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getUpdater--">getUpdater</a></span>()</code>
<div class="block">Get the updater for this MultiLayerNetwork</div>
</td>
</tr>
<tr id="i75" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#gradient--">gradient</a></span>()</code>
<div class="block">Calculate a gradient</div>
</td>
</tr>
<tr id="i76" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,java.lang.Double&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#gradientAndScore--">gradientAndScore</a></span>()</code>
<div class="block">Get the gradient and score</div>
</td>
</tr>
<tr id="i77" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#init--">init</a></span>()</code>
<div class="block">Initialize the MultiLayerNetwork.</div>
</td>
</tr>
<tr id="i78" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#init-org.nd4j.linalg.api.ndarray.INDArray-boolean-">init</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;parameters,
    boolean&nbsp;cloneParametersArray)</code>
<div class="block">Initialize the MultiLayerNetwork, optionally with an existing parameters array.</div>
</td>
</tr>
<tr id="i79" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#initGradientsView--">initGradientsView</a></span>()</code>
<div class="block">This method: initializes the flattened gradients array (used in backprop) and sets the appropriate subset in all layers.</div>
</td>
</tr>
<tr id="i80" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#initialize-org.nd4j.linalg.dataset.DataSet-">initialize</a></span>(org.nd4j.linalg.dataset.DataSet&nbsp;data)</code>
<div class="block">Sets the input and labels from this dataset</div>
</td>
</tr>
<tr id="i81" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#initializeLayers-org.nd4j.linalg.api.ndarray.INDArray-">initializeLayers</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</code>
<div class="block">Base class for initializing the neuralNets based on the input.</div>
</td>
</tr>
<tr id="i82" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#initParams--">initParams</a></span>()</code>
<div class="block">Initialize the parameters</div>
</td>
</tr>
<tr id="i83" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#input--">input</a></span>()</code>
<div class="block">The input/feature matrix for the model</div>
</td>
</tr>
<tr id="i84" class="altColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#intializeConfigurations--">intializeConfigurations</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i85" class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#isInitCalled--">isInitCalled</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i86" class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#isPretrainLayer--">isPretrainLayer</a></span>()</code>
<div class="block">Returns true if the layer can be trained in an unsupervised/pretrain manner (VAE, RBMs etc)</div>
</td>
</tr>
<tr id="i87" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#iterate-org.nd4j.linalg.api.ndarray.INDArray-">iterate</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</code>
<div class="block">Run one iteration</div>
</td>
</tr>
<tr id="i88" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#labelProbabilities-org.nd4j.linalg.api.ndarray.INDArray-">labelProbabilities</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;examples)</code>
<div class="block">Returns the probabilities for each label
 for each example row wise</div>
</td>
</tr>
<tr id="i89" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#merge-org.deeplearning4j.nn.api.Layer-int-">merge</a></span>(<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&nbsp;layer,
     int&nbsp;batchSize)</code>
<div class="block"><span class="deprecatedLabel">Deprecated.</span>&nbsp;
<div class="block"><span class="deprecationComment">Not supported and not used</span></div>
</div>
</td>
</tr>
<tr id="i90" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#merge-org.deeplearning4j.nn.multilayer.MultiLayerNetwork-int-">merge</a></span>(<a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" title="class in org.deeplearning4j.nn.multilayer">MultiLayerNetwork</a>&nbsp;network,
     int&nbsp;batchSize)</code>
<div class="block"><span class="deprecatedLabel">Deprecated.</span>&nbsp;
<div class="block"><span class="deprecationComment">As of 0.7.3 - Feb 2017. No longer used; parameter averaging is performed via alternative means/methods</span></div>
</div>
</td>
</tr>
<tr id="i91" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#numLabels--">numLabels</a></span>()</code>
<div class="block">Returns the number of possible labels</div>
</td>
</tr>
<tr id="i92" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#numParams--">numParams</a></span>()</code>
<div class="block">Returns a 1 x m vector where the vector is composed of
 a flattened vector of all of the weights for the
 various neuralNets and output layer</div>
</td>
</tr>
<tr id="i93" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#numParams-boolean-">numParams</a></span>(boolean&nbsp;backwards)</code>
<div class="block">the number of parameters for the model</div>
</td>
</tr>
<tr id="i94" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">output</a></span>(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator)</code>&nbsp;</td>
</tr>
<tr id="i95" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-boolean-">output</a></span>(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator,
      boolean&nbsp;train)</code>
<div class="block">Label the probabilities of the input</div>
</td>
</tr>
<tr id="i96" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output-org.nd4j.linalg.api.ndarray.INDArray-">output</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</code>
<div class="block">Label the probabilities of the input</div>
</td>
</tr>
<tr id="i97" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output-org.nd4j.linalg.api.ndarray.INDArray-boolean-">output</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
      boolean&nbsp;train)</code>
<div class="block">Label the probabilities of the input</div>
</td>
</tr>
<tr id="i98" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output-org.nd4j.linalg.api.ndarray.INDArray-boolean-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">output</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
      boolean&nbsp;train,
      org.nd4j.linalg.api.ndarray.INDArray&nbsp;featuresMask,
      org.nd4j.linalg.api.ndarray.INDArray&nbsp;labelsMask)</code>
<div class="block">Calculate the output of the network, with masking arrays.</div>
</td>
</tr>
<tr id="i99" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">output</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
      <a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;train)</code>
<div class="block">Label the probabilities of the input</div>
</td>
</tr>
<tr id="i100" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#params--">params</a></span>()</code>
<div class="block">Returns a 1 x m vector where the vector is composed of
 a flattened vector of all of the weights for the
 various neuralNets(w,hbias NOT VBIAS) and output layer</div>
</td>
</tr>
<tr id="i101" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#params-boolean-">params</a></span>(boolean&nbsp;backwardOnly)</code>
<div class="block">Returns a 1 x m vector where the vector is composed of
 a flattened vector of all of the weights for the
 various neuralNets(w,hbias NOT VBIAS) and output layer</div>
</td>
</tr>
<tr id="i102" class="altColor">
<td class="colFirst"><code>java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#paramTable--">paramTable</a></span>()</code>
<div class="block">The param table</div>
</td>
</tr>
<tr id="i103" class="rowColor">
<td class="colFirst"><code>java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#paramTable-boolean-">paramTable</a></span>(boolean&nbsp;backpropParamsOnly)</code>
<div class="block">Table of parameters by key, for backprop
 For many models (dense layers, etc) - all parameters are backprop parameters</div>
</td>
</tr>
<tr id="i104" class="altColor">
<td class="colFirst"><code>java.util.List&lt;java.lang.String&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#predict-org.nd4j.linalg.dataset.api.DataSet-">predict</a></span>(org.nd4j.linalg.dataset.api.DataSet&nbsp;dataSet)</code>
<div class="block">Return predicted label names</div>
</td>
</tr>
<tr id="i105" class="rowColor">
<td class="colFirst"><code>int[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#predict-org.nd4j.linalg.api.ndarray.INDArray-">predict</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;d)</code>
<div class="block">Returns the predictions for each example in the dataset</div>
</td>
</tr>
<tr id="i106" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#preOutput-org.nd4j.linalg.api.ndarray.INDArray-">preOutput</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;x)</code>
<div class="block">Raw activations</div>
</td>
</tr>
<tr id="i107" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#preOutput-org.nd4j.linalg.api.ndarray.INDArray-boolean-">preOutput</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;x,
         boolean&nbsp;training)</code>
<div class="block">Raw activations</div>
</td>
</tr>
<tr id="i108" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#preOutput-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">preOutput</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;x,
         <a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</code>
<div class="block">Raw activations</div>
</td>
</tr>
<tr id="i109" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrain-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">pretrain</a></span>(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iter)</code>
<div class="block">Perform layerwise pretraining on all pre-trainable layers in the network (VAEs, RBMs, Autoencoders, etc)<br>
 Note that pretraining will be performed on one layer after the other, resetting the DataSetIterator between iterations.<br>
 For multiple epochs per layer, appropriately wrap the iterator (for example, a MultipleEpochsIterator) or train
 each layer manually using <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrainLayer-int-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-"><code>pretrainLayer(int, DataSetIterator)</code></a></div>
</td>
</tr>
<tr id="i110" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrain-org.nd4j.linalg.api.ndarray.INDArray-">pretrain</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</code>
<div class="block"><span class="deprecatedLabel">Deprecated.</span>&nbsp;
<div class="block"><span class="deprecationComment">use <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrain-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-"><code>pretrain(DataSetIterator)</code></a> or <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrainLayer-int-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-"><code>pretrainLayer(int, DataSetIterator)</code></a> or <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrainLayer-int-org.nd4j.linalg.api.ndarray.INDArray-"><code>pretrainLayer(int, INDArray)</code></a>.
 Pretraining each layer in a row on a single minibatch (as per this method) instead of N epochs per layer is not advisable.</span></div>
</div>
</td>
</tr>
<tr id="i111" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrainLayer-int-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">pretrainLayer</a></span>(int&nbsp;layerIdx,
             org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iter)</code>
<div class="block">Perform layerwise unsupervised training on a single pre-trainable layer in the network (VAEs, RBMs, Autoencoders, etc)<br>
 If the specified layer index (0 to numLayers - 1) is not a pretrainable layer, this is a no-op.</div>
</td>
</tr>
<tr id="i112" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrainLayer-int-org.nd4j.linalg.api.ndarray.INDArray-">pretrainLayer</a></span>(int&nbsp;layerIdx,
             org.nd4j.linalg.api.ndarray.INDArray&nbsp;features)</code>
<div class="block">Perform layerwise unsupervised training on a single pre-trainable layer in the network (VAEs, RBMs, Autoencoders, etc)<br>
 If the specified layer index (0 to numLayers - 1) is not a pretrainable layer, this is a no-op.</div>
</td>
</tr>
<tr id="i113" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#printConfiguration--">printConfiguration</a></span>()</code>
<div class="block">Prints the configuration</div>
</td>
</tr>
<tr id="i114" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#reconstruct-org.nd4j.linalg.api.ndarray.INDArray-int-">reconstruct</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;x,
           int&nbsp;layerNum)</code>
<div class="block">Reconstructs the input.</div>
</td>
</tr>
<tr id="i115" class="rowColor">
<td class="colFirst"><code>java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#rnnActivateUsingStoredState-org.nd4j.linalg.api.ndarray.INDArray-boolean-boolean-">rnnActivateUsingStoredState</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
                           boolean&nbsp;training,
                           boolean&nbsp;storeLastForTBPTT)</code>
<div class="block">Similar to rnnTimeStep and feedForward() methods.</div>
</td>
</tr>
<tr id="i116" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#rnnClearPreviousState--">rnnClearPreviousState</a></span>()</code>
<div class="block">Clear the previous state of the RNN layers (if any).</div>
</td>
</tr>
<tr id="i117" class="rowColor">
<td class="colFirst"><code>java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#rnnGetPreviousState-int-">rnnGetPreviousState</a></span>(int&nbsp;layer)</code>
<div class="block">Get the state of the RNN layer, as used in rnnTimeStep().</div>
</td>
</tr>
<tr id="i118" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#rnnSetPreviousState-int-java.util.Map-">rnnSetPreviousState</a></span>(int&nbsp;layer,
                   java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;state)</code>
<div class="block">Set the state of the RNN layer.</div>
</td>
</tr>
<tr id="i119" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#rnnTimeStep-org.nd4j.linalg.api.ndarray.INDArray-">rnnTimeStep</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</code>
<div class="block">If this MultiLayerNetwork contains one or more RNN layers: conduct forward pass (prediction)
 but using previous stored state for any RNN layers.</div>
</td>
</tr>
<tr id="i120" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score--">score</a></span>()</code>
<div class="block">Score of the model (relative to the objective function)</div>
</td>
</tr>
<tr id="i121" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score-org.nd4j.linalg.dataset.DataSet-">score</a></span>(org.nd4j.linalg.dataset.DataSet&nbsp;data)</code>
<div class="block">Sets the input and labels and returns a score for the prediction with respect to the true labels<br>
 This is equivalent to <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score-org.nd4j.linalg.dataset.DataSet-boolean-"><code>score(DataSet, boolean)</code></a> with training==true.</div>
</td>
</tr>
<tr id="i122" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score-org.nd4j.linalg.dataset.DataSet-boolean-">score</a></span>(org.nd4j.linalg.dataset.DataSet&nbsp;data,
     boolean&nbsp;training)</code>
<div class="block">Calculate the score (loss function) of the prediction with respect to the true labels<br></div>
</td>
</tr>
<tr id="i123" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#scoreExamples-org.nd4j.linalg.dataset.DataSet-boolean-">scoreExamples</a></span>(org.nd4j.linalg.dataset.DataSet&nbsp;data,
             boolean&nbsp;addRegularizationTerms)</code>
<div class="block">Calculate the score for each example in a DataSet individually.</div>
</td>
</tr>
<tr id="i124" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#scoreExamples-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-boolean-">scoreExamples</a></span>(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iter,
             boolean&nbsp;addRegularizationTerms)</code>&nbsp;</td>
</tr>
<tr id="i125" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setBackpropGradientsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">setBackpropGradientsViewArray</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;gradients)</code>
<div class="block">Set the gradients array as a view of the full (backprop) network parameters
 NOTE: this is intended to be used internally in MultiLayerNetwork and ComputationGraph, not by users.</div>
</td>
</tr>
<tr id="i126" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setConf-org.deeplearning4j.nn.conf.NeuralNetConfiguration-">setConf</a></span>(<a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a>&nbsp;conf)</code>
<div class="block">Setter for the configuration</div>
</td>
</tr>
<tr id="i127" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setIndex-int-">setIndex</a></span>(int&nbsp;index)</code>
<div class="block">Set the layer index.</div>
</td>
</tr>
<tr id="i128" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setInput-org.nd4j.linalg.api.ndarray.INDArray-">setInput</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</code>
<div class="block">Note that if input isn't null
 and the neuralNets are null, this is a way
 of initializing the neural network</div>
</td>
</tr>
<tr id="i129" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setInputMiniBatchSize-int-">setInputMiniBatchSize</a></span>(int&nbsp;size)</code>
<div class="block">Set current/last input mini-batch size.<br>
 Used for score and gradient calculations.</div>
</td>
</tr>
<tr id="i130" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLabels-org.nd4j.linalg.api.ndarray.INDArray-">setLabels</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;labels)</code>&nbsp;</td>
</tr>
<tr id="i131" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLayerMaskArrays-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">setLayerMaskArrays</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;featuresMaskArray,
                  org.nd4j.linalg.api.ndarray.INDArray&nbsp;labelsMaskArray)</code>
<div class="block">Set the mask arrays for features and labels.</div>
</td>
</tr>
<tr id="i132" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLayers-org.deeplearning4j.nn.api.Layer:A-">setLayers</a></span>(<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>[]&nbsp;layers)</code>&nbsp;</td>
</tr>
<tr id="i133" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLayerWiseConfigurations-org.deeplearning4j.nn.conf.MultiLayerConfiguration-">setLayerWiseConfigurations</a></span>(<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;layerWiseConfigurations)</code>&nbsp;</td>
</tr>
<tr id="i134" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setListeners-java.util.Collection-">setListeners</a></span>(java.util.Collection&lt;<a href="../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>&gt;&nbsp;listeners)</code>
<div class="block">Set the IterationListeners for the ComputationGraph (and all layers in the network)</div>
</td>
</tr>
<tr id="i135" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setListeners-org.deeplearning4j.optimize.api.IterationListener...-">setListeners</a></span>(<a href="../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>...&nbsp;listeners)</code>
<div class="block">Set the IterationListeners for the ComputationGraph (and all layers in the network)</div>
</td>
</tr>
<tr id="i136" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setMask-org.nd4j.linalg.api.ndarray.INDArray-">setMask</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;mask)</code>&nbsp;</td>
</tr>
<tr id="i137" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setMaskArray-org.nd4j.linalg.api.ndarray.INDArray-">setMaskArray</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;maskArray)</code>
<div class="block">Set the mask array.</div>
</td>
</tr>
<tr id="i138" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setParam-java.lang.String-org.nd4j.linalg.api.ndarray.INDArray-">setParam</a></span>(java.lang.String&nbsp;key,
        org.nd4j.linalg.api.ndarray.INDArray&nbsp;val)</code>
<div class="block">Set the parameter with a new ndarray</div>
</td>
</tr>
<tr id="i139" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setParameters-org.nd4j.linalg.api.ndarray.INDArray-">setParameters</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;params)</code>
<div class="block">Sets parameters for the model.</div>
</td>
</tr>
<tr id="i140" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setParams-org.nd4j.linalg.api.ndarray.INDArray-">setParams</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;params)</code>
<div class="block">Set the parameters for this model.</div>
</td>
</tr>
<tr id="i141" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setParamsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">setParamsViewArray</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;params)</code>
<div class="block">Set the initial parameters array as a view of the full (backprop) network parameters
 NOTE: this is intended to be used internally in MultiLayerNetwork and ComputationGraph, not by users.</div>
</td>
</tr>
<tr id="i142" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setParamTable-java.util.Map-">setParamTable</a></span>(java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;paramTable)</code>
<div class="block">Setter for the param table</div>
</td>
</tr>
<tr id="i143" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setScore-double-">setScore</a></span>(double&nbsp;score)</code>&nbsp;</td>
</tr>
<tr id="i144" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setUpdater-org.deeplearning4j.nn.api.Updater-">setUpdater</a></span>(<a href="../../../../org/deeplearning4j/nn/api/Updater.html" title="interface in org.deeplearning4j.nn.api">Updater</a>&nbsp;updater)</code>
<div class="block">Set the updater for the MultiLayerNetwork</div>
</td>
</tr>
<tr id="i145" class="rowColor">
<td class="colFirst"><code>java.lang.String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#summary--">summary</a></span>()</code>
<div class="block">String detailing the architecture of the multilayernetwork.</div>
</td>
</tr>
<tr id="i146" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#transpose--">transpose</a></span>()</code>
<div class="block">Return a transposed copy of the weights/bias
 (this means reverse the number of inputs and outputs on the weights)</div>
</td>
</tr>
<tr id="i147" class="rowColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#truncatedBPTTGradient--">truncatedBPTTGradient</a></span>()</code>
<div class="block">Equivalent to backprop(), but calculates gradient for truncated BPTT instead.</div>
</td>
</tr>
<tr id="i148" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Layer.Type.html" title="enum in org.deeplearning4j.nn.api">Layer.Type</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#type--">type</a></span>()</code>
<div class="block">Returns the layer type</div>
</td>
</tr>
<tr id="i149" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#update-org.deeplearning4j.nn.gradient.Gradient-">update</a></span>(<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;gradient)</code>
<div class="block">Update layer weights and biases with gradient change</div>
</td>
</tr>
<tr id="i150" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#update-org.nd4j.linalg.api.ndarray.INDArray-java.lang.String-">update</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;gradient,
      java.lang.String&nbsp;paramType)</code>
<div class="block">Perform one update  applying the gradient</div>
</td>
</tr>
<tr id="i151" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#update-org.deeplearning4j.nn.multilayer.MultiLayerNetwork-">update</a></span>(<a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" title="class in org.deeplearning4j.nn.multilayer">MultiLayerNetwork</a>&nbsp;network)</code>
<div class="block">Assigns the parameters of this model to the ones specified by this
 network.</div>
</td>
</tr>
<tr id="i152" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#updateRnnStateWithTBPTTState--">updateRnnStateWithTBPTTState</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i153" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#validateInput--">validateInput</a></span>()</code>
<div class="block">Validate the input</div>
</td>
</tr>
<tr id="i154" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#zFromPrevLayer-int-org.nd4j.linalg.api.ndarray.INDArray-boolean-">zFromPrevLayer</a></span>(int&nbsp;curr,
              org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
              boolean&nbsp;training)</code>
<div class="block">Compute input linear transformation (z) from previous layer
 Apply pre processing transformation where necessary</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ FIELD DETAIL =========== -->
<ul class="blockList">
<li class="blockList"><a name="field.detail">
<!--   -->
</a>
<h3>Field Detail</h3>
<a name="layers">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>layers</h4>
<pre>protected&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>[] layers</pre>
</li>
</ul>
<a name="layerMap">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>layerMap</h4>
<pre>protected&nbsp;java.util.LinkedHashMap&lt;java.lang.String,<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&gt; layerMap</pre>
</li>
</ul>
<a name="input">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>input</h4>
<pre>protected&nbsp;org.nd4j.linalg.api.ndarray.INDArray input</pre>
</li>
</ul>
<a name="labels">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>labels</h4>
<pre>protected&nbsp;org.nd4j.linalg.api.ndarray.INDArray labels</pre>
</li>
</ul>
<a name="initCalled">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initCalled</h4>
<pre>protected&nbsp;boolean initCalled</pre>
</li>
</ul>
<a name="defaultConfiguration">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>defaultConfiguration</h4>
<pre>protected&nbsp;<a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a> defaultConfiguration</pre>
</li>
</ul>
<a name="layerWiseConfigurations">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>layerWiseConfigurations</h4>
<pre>protected&nbsp;<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a> layerWiseConfigurations</pre>
</li>
</ul>
<a name="gradient">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>gradient</h4>
<pre>protected&nbsp;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a> gradient</pre>
</li>
</ul>
<a name="epsilon">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>epsilon</h4>
<pre>protected&nbsp;org.nd4j.linalg.api.ndarray.INDArray epsilon</pre>
</li>
</ul>
<a name="score">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>score</h4>
<pre>protected&nbsp;double score</pre>
</li>
</ul>
<a name="initDone">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initDone</h4>
<pre>protected&nbsp;boolean initDone</pre>
</li>
</ul>
<a name="flattenedParams">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>flattenedParams</h4>
<pre>protected&nbsp;org.nd4j.linalg.api.ndarray.INDArray flattenedParams</pre>
</li>
</ul>
<a name="flattenedGradients">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>flattenedGradients</h4>
<pre>protected transient&nbsp;org.nd4j.linalg.api.ndarray.INDArray flattenedGradients</pre>
</li>
</ul>
<a name="mask">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mask</h4>
<pre>protected&nbsp;org.nd4j.linalg.api.ndarray.INDArray mask</pre>
</li>
</ul>
<a name="layerIndex">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>layerIndex</h4>
<pre>protected&nbsp;int layerIndex</pre>
</li>
</ul>
<a name="solver">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>solver</h4>
<pre>protected transient&nbsp;<a href="../../../../org/deeplearning4j/optimize/Solver.html" title="class in org.deeplearning4j.optimize">Solver</a> solver</pre>
</li>
</ul>
</li>
</ul>
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="MultiLayerNetwork-org.deeplearning4j.nn.conf.MultiLayerConfiguration-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>MultiLayerNetwork</h4>
<pre>public&nbsp;MultiLayerNetwork(<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;conf)</pre>
</li>
</ul>
<a name="MultiLayerNetwork-java.lang.String-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>MultiLayerNetwork</h4>
<pre>public&nbsp;MultiLayerNetwork(java.lang.String&nbsp;conf,
                         org.nd4j.linalg.api.ndarray.INDArray&nbsp;params)</pre>
<div class="block">Initialize the network based on the configuration</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>conf</code> - the configuration json</dd>
<dd><code>params</code> - the parameters</dd>
</dl>
</li>
</ul>
<a name="MultiLayerNetwork-org.deeplearning4j.nn.conf.MultiLayerConfiguration-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>MultiLayerNetwork</h4>
<pre>public&nbsp;MultiLayerNetwork(<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;conf,
                         org.nd4j.linalg.api.ndarray.INDArray&nbsp;params)</pre>
<div class="block">Initialize the network based on the configuraiton</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>conf</code> - the configuration</dd>
<dd><code>params</code> - the parameters</dd>
</dl>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="intializeConfigurations--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>intializeConfigurations</h4>
<pre>protected&nbsp;void&nbsp;intializeConfigurations()</pre>
</li>
</ul>
<a name="pretrain-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pretrain</h4>
<pre>public&nbsp;void&nbsp;pretrain(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iter)</pre>
<div class="block">Perform layerwise pretraining on all pre-trainable layers in the network (VAEs, RBMs, Autoencoders, etc)<br>
 Note that pretraining will be performed on one layer after the other, resetting the DataSetIterator between iterations.<br>
 For multiple epochs per layer, appropriately wrap the iterator (for example, a MultipleEpochsIterator) or train
 each layer manually using <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrainLayer-int-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-"><code>pretrainLayer(int, DataSetIterator)</code></a></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iter</code> - Training data</dd>
</dl>
</li>
</ul>
<a name="pretrainLayer-int-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pretrainLayer</h4>
<pre>public&nbsp;void&nbsp;pretrainLayer(int&nbsp;layerIdx,
                          org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iter)</pre>
<div class="block">Perform layerwise unsupervised training on a single pre-trainable layer in the network (VAEs, RBMs, Autoencoders, etc)<br>
 If the specified layer index (0 to numLayers - 1) is not a pretrainable layer, this is a no-op.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layerIdx</code> - Index of the layer to train (0 to numLayers-1)</dd>
<dd><code>iter</code> - Training data</dd>
</dl>
</li>
</ul>
<a name="pretrainLayer-int-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pretrainLayer</h4>
<pre>public&nbsp;void&nbsp;pretrainLayer(int&nbsp;layerIdx,
                          org.nd4j.linalg.api.ndarray.INDArray&nbsp;features)</pre>
<div class="block">Perform layerwise unsupervised training on a single pre-trainable layer in the network (VAEs, RBMs, Autoencoders, etc)<br>
 If the specified layer index (0 to numLayers - 1) is not a pretrainable layer, this is a no-op.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layerIdx</code> - Index of the layer to train (0 to numLayers-1)</dd>
<dd><code>features</code> - Training data array</dd>
</dl>
</li>
</ul>
<a name="pretrain-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pretrain</h4>
<pre>@Deprecated
public&nbsp;void&nbsp;pretrain(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</pre>
<div class="block"><span class="deprecatedLabel">Deprecated.</span>&nbsp;<span class="deprecationComment">use <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrain-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-"><code>pretrain(DataSetIterator)</code></a> or <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrainLayer-int-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-"><code>pretrainLayer(int, DataSetIterator)</code></a> or <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrainLayer-int-org.nd4j.linalg.api.ndarray.INDArray-"><code>pretrainLayer(int, INDArray)</code></a>.
 Pretraining each layer in a row on a single minibatch (as per this method) instead of N epochs per layer is not advisable.</span></div>
</li>
</ul>
<a name="batchSize--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>batchSize</h4>
<pre>public&nbsp;int&nbsp;batchSize()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#batchSize--">Model</a></code></span></div>
<div class="block">The current inputs batch size</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#batchSize--">batchSize</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the current inputs batch size</dd>
</dl>
</li>
</ul>
<a name="conf--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>conf</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a>&nbsp;conf()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#conf--">Model</a></code></span></div>
<div class="block">The configuration for the neural network</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#conf--">conf</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the configuration for the neural network</dd>
</dl>
</li>
</ul>
<a name="setConf-org.deeplearning4j.nn.conf.NeuralNetConfiguration-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setConf</h4>
<pre>public&nbsp;void&nbsp;setConf(<a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a>&nbsp;conf)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setConf-org.deeplearning4j.nn.conf.NeuralNetConfiguration-">Model</a></code></span></div>
<div class="block">Setter for the configuration</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setConf-org.deeplearning4j.nn.conf.NeuralNetConfiguration-">setConf</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="input--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>input</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;input()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#input--">Model</a></code></span></div>
<div class="block">The input/feature matrix for the model</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#input--">input</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the input/feature matrix for the model</dd>
</dl>
</li>
</ul>
<a name="validateInput--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>validateInput</h4>
<pre>public&nbsp;void&nbsp;validateInput()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#validateInput--">Model</a></code></span></div>
<div class="block">Validate the input</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#validateInput--">validateInput</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="getOptimizer--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getOptimizer</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/optimize/api/ConvexOptimizer.html" title="interface in org.deeplearning4j.optimize.api">ConvexOptimizer</a>&nbsp;getOptimizer()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#getOptimizer--">Model</a></code></span></div>
<div class="block">Returns this models optimizer</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#getOptimizer--">getOptimizer</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>this models optimizer</dd>
</dl>
</li>
</ul>
<a name="getParam-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getParam</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;getParam(java.lang.String&nbsp;param)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#getParam-java.lang.String-">Model</a></code></span></div>
<div class="block">Get the parameter</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#getParam-java.lang.String-">getParam</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>param</code> - the key of the parameter</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the parameter vector/matrix with that particular key</dd>
</dl>
</li>
</ul>
<a name="initParams--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initParams</h4>
<pre>public&nbsp;void&nbsp;initParams()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#initParams--">Model</a></code></span></div>
<div class="block">Initialize the parameters</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#initParams--">initParams</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="paramTable--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>paramTable</h4>
<pre>public&nbsp;java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;paramTable()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#paramTable--">Model</a></code></span></div>
<div class="block">The param table</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#paramTable--">paramTable</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="paramTable-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>paramTable</h4>
<pre>public&nbsp;java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;paramTable(boolean&nbsp;backpropParamsOnly)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#paramTable-boolean-">Model</a></code></span></div>
<div class="block">Table of parameters by key, for backprop
 For many models (dense layers, etc) - all parameters are backprop parameters</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#paramTable-boolean-">paramTable</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>backpropParamsOnly</code> - If true, return backprop params only. If false: return all params (equivalent to
                           paramsTable())</dd>
</dl>
</li>
</ul>
<a name="setParamTable-java.util.Map-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setParamTable</h4>
<pre>public&nbsp;void&nbsp;setParamTable(java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;paramTable)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setParamTable-java.util.Map-">Model</a></code></span></div>
<div class="block">Setter for the param table</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setParamTable-java.util.Map-">setParamTable</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="setParam-java.lang.String-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setParam</h4>
<pre>public&nbsp;void&nbsp;setParam(java.lang.String&nbsp;key,
                     org.nd4j.linalg.api.ndarray.INDArray&nbsp;val)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setParam-java.lang.String-org.nd4j.linalg.api.ndarray.INDArray-">Model</a></code></span></div>
<div class="block">Set the parameter with a new ndarray</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setParam-java.lang.String-org.nd4j.linalg.api.ndarray.INDArray-">setParam</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>key</code> - the key to se t</dd>
<dd><code>val</code> - the new ndarray</dd>
</dl>
</li>
</ul>
<a name="getLayerWiseConfigurations--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLayerWiseConfigurations</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;getLayerWiseConfigurations()</pre>
</li>
</ul>
<a name="setLayerWiseConfigurations-org.deeplearning4j.nn.conf.MultiLayerConfiguration-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLayerWiseConfigurations</h4>
<pre>public&nbsp;void&nbsp;setLayerWiseConfigurations(<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;layerWiseConfigurations)</pre>
</li>
</ul>
<a name="initializeLayers-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initializeLayers</h4>
<pre>public&nbsp;void&nbsp;initializeLayers(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</pre>
<div class="block">Base class for initializing the neuralNets based on the input.
 This is meant for capturing numbers such as input columns or other things.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input matrix for training</dd>
</dl>
</li>
</ul>
<a name="init--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>init</h4>
<pre>public&nbsp;void&nbsp;init()</pre>
<div class="block">Initialize the MultiLayerNetwork. This should be called once before the network is used.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#init--">init</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="init-org.nd4j.linalg.api.ndarray.INDArray-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>init</h4>
<pre>public&nbsp;void&nbsp;init(org.nd4j.linalg.api.ndarray.INDArray&nbsp;parameters,
                 boolean&nbsp;cloneParametersArray)</pre>
<div class="block">Initialize the MultiLayerNetwork, optionally with an existing parameters array.
 If an existing parameters array is specified, it will be used (and the values will not be modified) in the network;
 if no parameters array is specified, parameters will be initialized randomly according to the network configuration.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>parameters</code> - Network parameter. May be null. If null: randomly initialize.</dd>
<dd><code>cloneParametersArray</code> - Whether the parameter array (if any) should be cloned, or used directly</dd>
</dl>
</li>
</ul>
<a name="isInitCalled--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isInitCalled</h4>
<pre>public&nbsp;boolean&nbsp;isInitCalled()</pre>
</li>
</ul>
<a name="initGradientsView--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initGradientsView</h4>
<pre>public&nbsp;void&nbsp;initGradientsView()</pre>
<div class="block">This method: initializes the flattened gradients array (used in backprop) and sets the appropriate subset in all layers.
 As a general rule, this shouldn't ever need to be called manually when doing training via fit(DataSet) or fit(DataSetIterator)</div>
</li>
</ul>
<a name="activate--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;activate()</pre>
<div class="block">Triggers the activation of the last hidden layer ie: not logistic regression</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate--">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the activation of the last hidden layer given the last input to the network</dd>
</dl>
</li>
</ul>
<a name="activate-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;activate(int&nbsp;layer)</pre>
<div class="block">Triggers the activation for a given layer</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layer</code> - the layer to activate on</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the activation for a given layer</dd>
</dl>
</li>
</ul>
<a name="activate-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;activate(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate-org.nd4j.linalg.api.ndarray.INDArray-">Layer</a></code></span></div>
<div class="block">Initialize the layer with the given input
 and return the activation for this layer
 given this input</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate-org.nd4j.linalg.api.ndarray.INDArray-">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input to use</dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="activate-int-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;activate(int&nbsp;layer,
                                                     org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</pre>
<div class="block">Triggers the activation of the given layer</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layer</code> - the layer to trigger on</dd>
<dd><code>input</code> - the input to the hidden layer</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the activation of the layer based on the input</dd>
</dl>
</li>
</ul>
<a name="activationMean--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activationMean</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;activationMean()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activationMean--">Layer</a></code></span></div>
<div class="block">Calculate the mean representation
 for the activation for this layer</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activationMean--">activationMean</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the activation mean for this layer</dd>
</dl>
</li>
</ul>
<a name="initialize-org.nd4j.linalg.dataset.DataSet-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initialize</h4>
<pre>public&nbsp;void&nbsp;initialize(org.nd4j.linalg.dataset.DataSet&nbsp;data)</pre>
<div class="block">Sets the input and labels from this dataset</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - the dataset to initialize with</dd>
</dl>
</li>
</ul>
<a name="zFromPrevLayer-int-org.nd4j.linalg.api.ndarray.INDArray-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>zFromPrevLayer</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;zFromPrevLayer(int&nbsp;curr,
                                                           org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
                                                           boolean&nbsp;training)</pre>
<div class="block">Compute input linear transformation (z) from previous layer
 Apply pre processing transformation where necessary</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>curr</code> - the current layer</dd>
<dd><code>input</code> - the input</dd>
<dd><code>training</code> - training or test mode</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the activation from the previous layer</dd>
</dl>
</li>
</ul>
<a name="activationFromPrevLayer-int-org.nd4j.linalg.api.ndarray.INDArray-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activationFromPrevLayer</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;activationFromPrevLayer(int&nbsp;curr,
                                                                    org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
                                                                    boolean&nbsp;training)</pre>
<div class="block">Calculate activation from previous layer including pre processing where necessary</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>curr</code> - the current layer</dd>
<dd><code>input</code> - the input</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the activation from the previous layer</dd>
</dl>
</li>
</ul>
<a name="activateSelectedLayers-int-int-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activateSelectedLayers</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;activateSelectedLayers(int&nbsp;from,
                                                                   int&nbsp;to,
                                                                   org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</pre>
<div class="block">Calculate activation for few layers at once. Suitable for autoencoder partial activation.

 In example: in 10-layer deep autoencoder, layers 0 - 4 inclusive are used for encoding part, and layers 5-9 inclusive are used for decoding part.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>from</code> - first layer to be activated, inclusive</dd>
<dd><code>to</code> - last layer to be activated, inclusive</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the activation from the last layer</dd>
</dl>
</li>
</ul>
<a name="computeZ-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>computeZ</h4>
<pre>public&nbsp;java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;computeZ(boolean&nbsp;training)</pre>
<div class="block">* Compute input linear transformation (z) of the output layer</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the list of activations for each layer</dd>
</dl>
</li>
</ul>
<a name="computeZ-org.nd4j.linalg.api.ndarray.INDArray-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>computeZ</h4>
<pre>public&nbsp;java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;computeZ(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
                                                                     boolean&nbsp;training)</pre>
<div class="block">Compute activations from input to output of the output layer</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the list of activations for each layer</dd>
</dl>
</li>
</ul>
<a name="feedForward-org.nd4j.linalg.api.ndarray.INDArray-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForward</h4>
<pre>public&nbsp;java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;feedForward(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
                                                                        boolean&nbsp;train)</pre>
<div class="block">Compute activations from input to output of the output layer</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the list of activations for each layer</dd>
</dl>
</li>
</ul>
<a name="feedForward-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForward</h4>
<pre>public&nbsp;java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;feedForward(boolean&nbsp;train)</pre>
<div class="block">Compute activations from input to output of the output layer</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the list of activations for each layer</dd>
</dl>
</li>
</ul>
<a name="feedForwardToLayer-int-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForwardToLayer</h4>
<pre>public&nbsp;java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;feedForwardToLayer(int&nbsp;layerNum,
                                                                               org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</pre>
<div class="block">Compute the activations from the input to the specified layer.<br>
 To compute activations for all layers, use feedForward(...) methods<br>
 Note: output list includes the original input. So list.get(0) is always the original input, and
 list.get(i+1) is the activations of the ith layer.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layerNum</code> - Index of the last layer to calculate activations for. Layers are zero-indexed.
                 feedForwardToLayer(i,input) will return the activations for layers 0..i (inclusive)</dd>
<dd><code>input</code> - Input to the network</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>list of activations.</dd>
</dl>
</li>
</ul>
<a name="feedForwardToLayer-int-org.nd4j.linalg.api.ndarray.INDArray-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForwardToLayer</h4>
<pre>public&nbsp;java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;feedForwardToLayer(int&nbsp;layerNum,
                                                                               org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
                                                                               boolean&nbsp;train)</pre>
<div class="block">Compute the activations from the input to the specified layer.<br>
 To compute activations for all layers, use feedForward(...) methods<br>
 Note: output list includes the original input. So list.get(0) is always the original input, and
 list.get(i+1) is the activations of the ith layer.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layerNum</code> - Index of the last layer to calculate activations for. Layers are zero-indexed.
                 feedForwardToLayer(i,input) will return the activations for layers 0..i (inclusive)</dd>
<dd><code>input</code> - Input to the network</dd>
<dd><code>train</code> - true for training, false for test (i.e., false if using network after training)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>list of activations.</dd>
</dl>
</li>
</ul>
<a name="feedForwardToLayer-int-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForwardToLayer</h4>
<pre>public&nbsp;java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;feedForwardToLayer(int&nbsp;layerNum,
                                                                               boolean&nbsp;train)</pre>
<div class="block">Compute the activations from the input to the specified layer, using the currently set input for the network.<br>
 To compute activations for all layers, use feedForward(...) methods<br>
 Note: output list includes the original input. So list.get(0) is always the original input, and
 list.get(i+1) is the activations of the ith layer.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layerNum</code> - Index of the last layer to calculate activations for. Layers are zero-indexed.
                 feedForwardToLayer(i,input) will return the activations for layers 0..i (inclusive)</dd>
<dd><code>train</code> - true for training, false for test (i.e., false if using network after training)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>list of activations.</dd>
</dl>
</li>
</ul>
<a name="feedForward--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForward</h4>
<pre>public&nbsp;java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;feedForward()</pre>
<div class="block">Compute activations from input to output of the output layer</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the list of activations for each layer</dd>
</dl>
</li>
</ul>
<a name="feedForward-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForward</h4>
<pre>public&nbsp;java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;feedForward(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</pre>
<div class="block">Compute activations from input to output of the output layer</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the list of activations for each layer</dd>
</dl>
</li>
</ul>
<a name="feedForward-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForward</h4>
<pre>public&nbsp;java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;feedForward(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
                                                                        org.nd4j.linalg.api.ndarray.INDArray&nbsp;featuresMask,
                                                                        org.nd4j.linalg.api.ndarray.INDArray&nbsp;labelsMask)</pre>
<div class="block">Compute the activations from the input to the output layer, given mask arrays (that may be null)
 The masking arrays are used in situations such an one-to-many and many-to-one rucerrent neural network (RNN)
 designs, as well as for supporting time series of varying lengths within the same minibatch for RNNs.</div>
</li>
</ul>
<a name="gradient--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>gradient</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;gradient()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#gradient--">Model</a></code></span></div>
<div class="block">Calculate a gradient</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#gradient--">gradient</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the gradient for this model</dd>
</dl>
</li>
</ul>
<a name="epsilon--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>epsilon</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;epsilon()</pre>
</li>
</ul>
<a name="gradientAndScore--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>gradientAndScore</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,java.lang.Double&gt;&nbsp;gradientAndScore()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#gradientAndScore--">Model</a></code></span></div>
<div class="block">Get the gradient and score</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#gradientAndScore--">gradientAndScore</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the gradient and score</dd>
</dl>
</li>
</ul>
<a name="clone--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clone</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" title="class in org.deeplearning4j.nn.multilayer">MultiLayerNetwork</a>&nbsp;clone()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#clone--">Layer</a></code></span></div>
<div class="block">Clone the layer</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#clone--">clone</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="overrideSpecifyLabel">Overrides:</span></dt>
<dd><code>clone</code>&nbsp;in class&nbsp;<code>java.lang.Object</code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="params-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>params</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;params(boolean&nbsp;backwardOnly)</pre>
<div class="block">Returns a 1 x m vector where the vector is composed of
 a flattened vector of all of the weights for the
 various neuralNets(w,hbias NOT VBIAS) and output layer</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the params for this neural net</dd>
</dl>
</li>
</ul>
<a name="params--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>params</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;params()</pre>
<div class="block">Returns a 1 x m vector where the vector is composed of
 a flattened vector of all of the weights for the
 various neuralNets(w,hbias NOT VBIAS) and output layer</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#params--">params</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the params for this neural net</dd>
</dl>
</li>
</ul>
<a name="setParams-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setParams</h4>
<pre>public&nbsp;void&nbsp;setParams(org.nd4j.linalg.api.ndarray.INDArray&nbsp;params)</pre>
<div class="block">Set the parameters for this model.
 This expects a linear ndarray
 which then be unpacked internally
 relative to the expected ordering of the model</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setParams-org.nd4j.linalg.api.ndarray.INDArray-">setParams</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>params</code> - the parameters for the model</dd>
</dl>
</li>
</ul>
<a name="setParamsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setParamsViewArray</h4>
<pre>public&nbsp;void&nbsp;setParamsViewArray(org.nd4j.linalg.api.ndarray.INDArray&nbsp;params)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setParamsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">Model</a></code></span></div>
<div class="block">Set the initial parameters array as a view of the full (backprop) network parameters
 NOTE: this is intended to be used internally in MultiLayerNetwork and ComputationGraph, not by users.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setParamsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">setParamsViewArray</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>params</code> - a 1 x nParams row vector that is a view of the larger (MLN/CG) parameters array</dd>
</dl>
</li>
</ul>
<a name="setBackpropGradientsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setBackpropGradientsViewArray</h4>
<pre>public&nbsp;void&nbsp;setBackpropGradientsViewArray(org.nd4j.linalg.api.ndarray.INDArray&nbsp;gradients)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setBackpropGradientsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">Model</a></code></span></div>
<div class="block">Set the gradients array as a view of the full (backprop) network parameters
 NOTE: this is intended to be used internally in MultiLayerNetwork and ComputationGraph, not by users.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setBackpropGradientsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">setBackpropGradientsViewArray</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>gradients</code> - a 1 x nParams row vector that is a view of the larger (MLN/CG) gradients array</dd>
</dl>
</li>
</ul>
<a name="numParams--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numParams</h4>
<pre>public&nbsp;int&nbsp;numParams()</pre>
<div class="block">Returns a 1 x m vector where the vector is composed of
 a flattened vector of all of the weights for the
 various neuralNets and output layer</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#numParams--">numParams</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the params for this neural net</dd>
</dl>
</li>
</ul>
<a name="numParams-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numParams</h4>
<pre>public&nbsp;int&nbsp;numParams(boolean&nbsp;backwards)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#numParams-boolean-">Model</a></code></span></div>
<div class="block">the number of parameters for the model</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#numParams-boolean-">numParams</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the number of parameters for the model</dd>
</dl>
</li>
</ul>
<a name="f1Score-org.nd4j.linalg.dataset.api.DataSet-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>f1Score</h4>
<pre>public&nbsp;double&nbsp;f1Score(org.nd4j.linalg.dataset.api.DataSet&nbsp;data)</pre>
<div class="block">Sets the input and labels and returns a score for the prediction
 wrt true labels</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#f1Score-org.nd4j.linalg.dataset.api.DataSet-">f1Score</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - the data to score</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the score for the given input,label pairs</dd>
</dl>
</li>
</ul>
<a name="fit-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#fit-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">Classifier</a></code></span></div>
<div class="block">Train the model based on the datasetiterator</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#fit-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - the iterator to train on</dd>
</dl>
</li>
</ul>
<a name="backprop--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>backprop</h4>
<pre>protected&nbsp;void&nbsp;backprop()</pre>
<div class="block">Calculate and set gradients for MultiLayerNetwork, based on OutputLayer and labels</div>
</li>
</ul>
<a name="calcBackpropGradients-org.nd4j.linalg.api.ndarray.INDArray-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calcBackpropGradients</h4>
<pre>protected&nbsp;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;calcBackpropGradients(org.nd4j.linalg.api.ndarray.INDArray&nbsp;epsilon,
                                                                                    boolean&nbsp;withOutputLayer)</pre>
<div class="block">Calculate gradients and errors. Used in two places:
 (a) backprop (for standard multi layer network learning)
 (b) backpropGradient (layer method, for when MultiLayerNetwork is used as a layer)</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>epsilon</code> - Errors (technically errors .* activations). Not used if withOutputLayer = true</dd>
<dd><code>withOutputLayer</code> - if true: assume last layer is output layer, and calculate errors based on labels. In this
                        case, the epsilon input is not used (may/should be null).
                        If false: calculate backprop gradients</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Gradients and the error (epsilon) at the input</dd>
</dl>
</li>
</ul>
<a name="doTruncatedBPTT-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>doTruncatedBPTT</h4>
<pre>protected&nbsp;void&nbsp;doTruncatedBPTT(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
                               org.nd4j.linalg.api.ndarray.INDArray&nbsp;labels,
                               org.nd4j.linalg.api.ndarray.INDArray&nbsp;featuresMaskArray,
                               org.nd4j.linalg.api.ndarray.INDArray&nbsp;labelsMaskArray)</pre>
</li>
</ul>
<a name="updateRnnStateWithTBPTTState--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>updateRnnStateWithTBPTTState</h4>
<pre>public&nbsp;void&nbsp;updateRnnStateWithTBPTTState()</pre>
</li>
</ul>
<a name="truncatedBPTTGradient--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>truncatedBPTTGradient</h4>
<pre>protected&nbsp;void&nbsp;truncatedBPTTGradient()</pre>
<div class="block">Equivalent to backprop(), but calculates gradient for truncated BPTT instead.</div>
</li>
</ul>
<a name="getListeners--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getListeners</h4>
<pre>public&nbsp;java.util.Collection&lt;<a href="../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>&gt;&nbsp;getListeners()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getListeners--">Layer</a></code></span></div>
<div class="block">Get the iteration listeners for this layer.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getListeners--">getListeners</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="setListeners-java.util.Collection-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setListeners</h4>
<pre>public&nbsp;void&nbsp;setListeners(java.util.Collection&lt;<a href="../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>&gt;&nbsp;listeners)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setListeners-java.util.Collection-">Model</a></code></span></div>
<div class="block">Set the IterationListeners for the ComputationGraph (and all layers in the network)</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setListeners-java.util.Collection-">setListeners</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setListeners-java.util.Collection-">setListeners</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="setListeners-org.deeplearning4j.optimize.api.IterationListener...-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setListeners</h4>
<pre>public&nbsp;void&nbsp;setListeners(<a href="../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>...&nbsp;listeners)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setListeners-org.deeplearning4j.optimize.api.IterationListener...-">Model</a></code></span></div>
<div class="block">Set the IterationListeners for the ComputationGraph (and all layers in the network)</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setListeners-org.deeplearning4j.optimize.api.IterationListener...-">setListeners</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setListeners-org.deeplearning4j.optimize.api.IterationListener...-">setListeners</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="finetune--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>finetune</h4>
<pre>public&nbsp;void&nbsp;finetune()</pre>
<div class="block">Run SGD based on the given labels</div>
</li>
</ul>
<a name="predict-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>predict</h4>
<pre>public&nbsp;int[]&nbsp;predict(org.nd4j.linalg.api.ndarray.INDArray&nbsp;d)</pre>
<div class="block">Returns the predictions for each example in the dataset</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#predict-org.nd4j.linalg.api.ndarray.INDArray-">predict</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>d</code> - the matrix to predict</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the prediction for the dataset</dd>
</dl>
</li>
</ul>
<a name="predict-org.nd4j.linalg.dataset.api.DataSet-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>predict</h4>
<pre>public&nbsp;java.util.List&lt;java.lang.String&gt;&nbsp;predict(org.nd4j.linalg.dataset.api.DataSet&nbsp;dataSet)</pre>
<div class="block">Return predicted label names</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#predict-org.nd4j.linalg.dataset.api.DataSet-">predict</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>dataSet</code> - to predict</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the predicted labels for the dataSet</dd>
</dl>
</li>
</ul>
<a name="labelProbabilities-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>labelProbabilities</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;labelProbabilities(org.nd4j.linalg.api.ndarray.INDArray&nbsp;examples)</pre>
<div class="block">Returns the probabilities for each label
 for each example row wise</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#labelProbabilities-org.nd4j.linalg.api.ndarray.INDArray-">labelProbabilities</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>examples</code> - the examples to classify (one example in each row)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the likelihoods of each example and each label</dd>
</dl>
</li>
</ul>
<a name="fit-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(org.nd4j.linalg.api.ndarray.INDArray&nbsp;data,
                org.nd4j.linalg.api.ndarray.INDArray&nbsp;labels)</pre>
<div class="block">Fit the model</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#fit-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - the examples to classify (one example in each row)</dd>
<dd><code>labels</code> - the example labels(a binary outcome matrix)</dd>
</dl>
</li>
</ul>
<a name="fit-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(org.nd4j.linalg.api.ndarray.INDArray&nbsp;features,
                org.nd4j.linalg.api.ndarray.INDArray&nbsp;labels,
                org.nd4j.linalg.api.ndarray.INDArray&nbsp;featuresMask,
                org.nd4j.linalg.api.ndarray.INDArray&nbsp;labelsMask)</pre>
<div class="block">Fit the model</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>features</code> - the examples to classify (one example in each row)</dd>
<dd><code>labels</code> - the example labels(a binary outcome matrix)</dd>
<dd><code>featuresMask</code> - The mask array for the features (used for variable length time series, etc). May be null.</dd>
<dd><code>labelsMask</code> - The mask array for the labels (used for variable length time series, etc). May be null.</dd>
</dl>
</li>
</ul>
<a name="fit-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(org.nd4j.linalg.api.ndarray.INDArray&nbsp;data)</pre>
<div class="block">Fit the unsupervised model</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#fit-org.nd4j.linalg.api.ndarray.INDArray-">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - the examples to classify (one example in each row)</dd>
</dl>
</li>
</ul>
<a name="iterate-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>iterate</h4>
<pre>public&nbsp;void&nbsp;iterate(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#iterate-org.nd4j.linalg.api.ndarray.INDArray-">Model</a></code></span></div>
<div class="block">Run one iteration</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#iterate-org.nd4j.linalg.api.ndarray.INDArray-">iterate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input to iterate on</dd>
</dl>
</li>
</ul>
<a name="fit-org.nd4j.linalg.dataset.api.DataSet-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(org.nd4j.linalg.dataset.api.DataSet&nbsp;data)</pre>
<div class="block">Fit the model</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#fit-org.nd4j.linalg.dataset.api.DataSet-">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - the data to train on</dd>
</dl>
</li>
</ul>
<a name="fit-org.nd4j.linalg.api.ndarray.INDArray-int:A-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(org.nd4j.linalg.api.ndarray.INDArray&nbsp;examples,
                int[]&nbsp;labels)</pre>
<div class="block">Fit the model</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#fit-org.nd4j.linalg.api.ndarray.INDArray-int:A-">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>examples</code> - the examples to classify (one example in each row)</dd>
<dd><code>labels</code> - the labels for each example (the number of labels must match</dd>
</dl>
</li>
</ul>
<a name="output-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>output</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;output(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
                                                   <a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;train)</pre>
<div class="block">Label the probabilities of the input</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input to label</dd>
<dd><code>train</code> - whether the output
             is test or train. This mainly
             affect hyper parameters such as
             drop out where certain things should
             be applied with activations</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>a vector of probabilities
 given each label.
 <p>
 This is typically of the form:
 [0.5, 0.5] or some other probability distribution summing to one</dd>
</dl>
</li>
</ul>
<a name="output-org.nd4j.linalg.api.ndarray.INDArray-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>output</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;output(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
                                                   boolean&nbsp;train)</pre>
<div class="block">Label the probabilities of the input</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input to label</dd>
<dd><code>train</code> - whether the output
             is test or train. This mainly
             affect hyper parameters such as
             drop out where certain things should
             be applied with activations</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>a vector of probabilities
 given each label.
 <p>
 This is typically of the form:
 [0.5, 0.5] or some other probability distribution summing to one</dd>
</dl>
</li>
</ul>
<a name="output-org.nd4j.linalg.api.ndarray.INDArray-boolean-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>output</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;output(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
                                                   boolean&nbsp;train,
                                                   org.nd4j.linalg.api.ndarray.INDArray&nbsp;featuresMask,
                                                   org.nd4j.linalg.api.ndarray.INDArray&nbsp;labelsMask)</pre>
<div class="block">Calculate the output of the network, with masking arrays. The masking arrays are used in situations such
 as one-to-many and many-to-one recurrent neural network (RNN) designs, as well as for supporting time series
 of varying lengths within the same minibatch.</div>
</li>
</ul>
<a name="output-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>output</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;output(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</pre>
<div class="block">Label the probabilities of the input</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input to label</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>a vector of probabilities
 given each label.
 <p>
 This is typically of the form:
 [0.5, 0.5] or some other probability distribution summing to one</dd>
</dl>
</li>
</ul>
<a name="output-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>output</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;output(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator,
                                                   boolean&nbsp;train)</pre>
<div class="block">Label the probabilities of the input</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - test data to evaluate</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>a vector of probabilities
 given each label.
 <p>
 This is typically of the form:
 [0.5, 0.5] or some other probability distribution summing to one</dd>
</dl>
</li>
</ul>
<a name="output-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>output</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;output(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator)</pre>
</li>
</ul>
<a name="reconstruct-org.nd4j.linalg.api.ndarray.INDArray-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reconstruct</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;reconstruct(org.nd4j.linalg.api.ndarray.INDArray&nbsp;x,
                                                        int&nbsp;layerNum)</pre>
<div class="block">Reconstructs the input.
 This is equivalent functionality to a
 deep autoencoder.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>x</code> - the input to transform</dd>
<dd><code>layerNum</code> - the layer to output for encoding</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>a reconstructed matrix
 relative to the size of the last hidden layer.
 This is great for data compression and visualizing
 high dimensional data (or just doing dimensionality reduction).
 <p>
 This is typically of the form:
 [0.5, 0.5] or some other probability distribution summing to one</dd>
</dl>
</li>
</ul>
<a name="printConfiguration--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>printConfiguration</h4>
<pre>public&nbsp;void&nbsp;printConfiguration()</pre>
<div class="block">Prints the configuration</div>
</li>
</ul>
<a name="update-org.deeplearning4j.nn.multilayer.MultiLayerNetwork-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>update</h4>
<pre>public&nbsp;void&nbsp;update(<a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" title="class in org.deeplearning4j.nn.multilayer">MultiLayerNetwork</a>&nbsp;network)</pre>
<div class="block">Assigns the parameters of this model to the ones specified by this
 network. This is used in loading from input streams, factory methods, etc</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>network</code> - the network to getFromOrigin parameters from</dd>
</dl>
</li>
</ul>
<a name="f1Score-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>f1Score</h4>
<pre>public&nbsp;double&nbsp;f1Score(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
                      org.nd4j.linalg.api.ndarray.INDArray&nbsp;labels)</pre>
<div class="block">Sets the input and labels and returns a score for the prediction
 wrt true labels</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#f1Score-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">f1Score</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input to score</dd>
<dd><code>labels</code> - the true labels</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the score for the given input,label pairs</dd>
</dl>
</li>
</ul>
<a name="numLabels--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numLabels</h4>
<pre>public&nbsp;int&nbsp;numLabels()</pre>
<div class="block">Returns the number of possible labels</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#numLabels--">numLabels</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the number of possible labels for this classifier</dd>
</dl>
</li>
</ul>
<a name="score-org.nd4j.linalg.dataset.DataSet-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>score</h4>
<pre>public&nbsp;double&nbsp;score(org.nd4j.linalg.dataset.DataSet&nbsp;data)</pre>
<div class="block">Sets the input and labels and returns a score for the prediction with respect to the true labels<br>
 This is equivalent to <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score-org.nd4j.linalg.dataset.DataSet-boolean-"><code>score(DataSet, boolean)</code></a> with training==true.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - the data to score</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the score for the given input,label pairs</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score-org.nd4j.linalg.dataset.DataSet-boolean-"><code>score(DataSet, boolean)</code></a></dd>
</dl>
</li>
</ul>
<a name="score-org.nd4j.linalg.dataset.DataSet-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>score</h4>
<pre>public&nbsp;double&nbsp;score(org.nd4j.linalg.dataset.DataSet&nbsp;data,
                    boolean&nbsp;training)</pre>
<div class="block">Calculate the score (loss function) of the prediction with respect to the true labels<br></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - data to calculate score for</dd>
<dd><code>training</code> - If true: score during training. If false: score at test time. This can affect the application of
                 certain features, such as dropout and dropconnect (which are applied at training time only)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the score (value of the loss function)</dd>
</dl>
</li>
</ul>
<a name="scoreExamples-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>scoreExamples</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;scoreExamples(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iter,
                                                          boolean&nbsp;addRegularizationTerms)</pre>
</li>
</ul>
<a name="scoreExamples-org.nd4j.linalg.dataset.DataSet-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>scoreExamples</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;scoreExamples(org.nd4j.linalg.dataset.DataSet&nbsp;data,
                                                          boolean&nbsp;addRegularizationTerms)</pre>
<div class="block">Calculate the score for each example in a DataSet individually. Unlike <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score-org.nd4j.linalg.dataset.DataSet-"><code>score(DataSet)</code></a> and <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score-org.nd4j.linalg.dataset.DataSet-boolean-"><code>score(DataSet, boolean)</code></a>
 this method does not average/sum over examples. This method allows for examples to be scored individually (at test time only), which
 may be useful for example for autoencoder architectures and the like.<br>
 Each row of the output (assuming addRegularizationTerms == true) is equivalent to calling score(DataSet) with a single example.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - The data to score</dd>
<dd><code>addRegularizationTerms</code> - If true: add l1/l2 regularization terms (if any) to the score. If false: don't add regularization terms</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>An INDArray (column vector) of size input.numRows(); the ith entry is the score (loss value) of the ith example</dd>
</dl>
</li>
</ul>
<a name="fit--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#fit--">Model</a></code></span></div>
<div class="block">All models have a fit method</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#fit--">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="update-org.nd4j.linalg.api.ndarray.INDArray-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>update</h4>
<pre>public&nbsp;void&nbsp;update(org.nd4j.linalg.api.ndarray.INDArray&nbsp;gradient,
                   java.lang.String&nbsp;paramType)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#update-org.nd4j.linalg.api.ndarray.INDArray-java.lang.String-">Model</a></code></span></div>
<div class="block">Perform one update  applying the gradient</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#update-org.nd4j.linalg.api.ndarray.INDArray-java.lang.String-">update</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>gradient</code> - the gradient to apply</dd>
</dl>
</li>
</ul>
<a name="score--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>score</h4>
<pre>public&nbsp;double&nbsp;score()</pre>
<div class="block">Score of the model (relative to the objective function)</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#score--">score</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the score of the model (relative to the objective function)</dd>
</dl>
</li>
</ul>
<a name="setScore-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setScore</h4>
<pre>public&nbsp;void&nbsp;setScore(double&nbsp;score)</pre>
</li>
</ul>
<a name="computeGradientAndScore--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>computeGradientAndScore</h4>
<pre>public&nbsp;void&nbsp;computeGradientAndScore()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#computeGradientAndScore--">Model</a></code></span></div>
<div class="block">Update the score</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#computeGradientAndScore--">computeGradientAndScore</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="accumulateScore-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>accumulateScore</h4>
<pre>public&nbsp;void&nbsp;accumulateScore(double&nbsp;accum)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#accumulateScore-double-">Model</a></code></span></div>
<div class="block">Sets a rolling tally for the score. This is useful for mini batch learning when
 you are accumulating error across a dataset.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#accumulateScore-double-">accumulateScore</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>accum</code> - the amount to accum</dd>
</dl>
</li>
</ul>
<a name="clear--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clear</h4>
<pre>public&nbsp;void&nbsp;clear()</pre>
<div class="block">Clear the inputs. Clears optimizer state.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#clear--">clear</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="merge-org.deeplearning4j.nn.api.Layer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>merge</h4>
<pre>@Deprecated
public&nbsp;void&nbsp;merge(<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&nbsp;layer,
                              int&nbsp;batchSize)</pre>
<div class="block"><span class="deprecatedLabel">Deprecated.</span>&nbsp;<span class="deprecationComment">Not supported and not used</span></div>
<div class="block">Averages the given logistic regression
 from a mini batch in to this one</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#merge-org.deeplearning4j.nn.api.Layer-int-">merge</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layer</code> - the logistic regression to average in to this one</dd>
<dd><code>batchSize</code> - the batch size</dd>
</dl>
</li>
</ul>
<a name="merge-org.deeplearning4j.nn.multilayer.MultiLayerNetwork-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>merge</h4>
<pre>@Deprecated
public&nbsp;void&nbsp;merge(<a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" title="class in org.deeplearning4j.nn.multilayer">MultiLayerNetwork</a>&nbsp;network,
                              int&nbsp;batchSize)</pre>
<div class="block"><span class="deprecatedLabel">Deprecated.</span>&nbsp;<span class="deprecationComment">As of 0.7.3 - Feb 2017. No longer used; parameter averaging is performed via alternative means/methods</span></div>
<div class="block">Deprecated: Merges this network with the other one.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>network</code> - the network to merge with</dd>
<dd><code>batchSize</code> - the batch size (number of training examples)
                  to average by</dd>
</dl>
</li>
</ul>
<a name="setInput-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setInput</h4>
<pre>public&nbsp;void&nbsp;setInput(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</pre>
<div class="block">Note that if input isn't null
 and the neuralNets are null, this is a way
 of initializing the neural network</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setInput-org.nd4j.linalg.api.ndarray.INDArray-">setInput</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - </dd>
</dl>
</li>
</ul>
<a name="getOutputLayer--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getOutputLayer</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&nbsp;getOutputLayer()</pre>
<div class="block">Get the output layer</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="setParameters-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setParameters</h4>
<pre>public&nbsp;void&nbsp;setParameters(org.nd4j.linalg.api.ndarray.INDArray&nbsp;params)</pre>
<div class="block">Sets parameters for the model.
 This is used to manipulate the weights and biases across
 all neuralNets (including the output layer)</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>params</code> - a parameter vector equal 1,numParameters</dd>
</dl>
</li>
</ul>
<a name="applyLearningRateScoreDecay--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>applyLearningRateScoreDecay</h4>
<pre>public&nbsp;void&nbsp;applyLearningRateScoreDecay()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#applyLearningRateScoreDecay--">Model</a></code></span></div>
<div class="block">Update learningRate using for this model.
 Use the learningRateScoreBasedDecay to adapt the score
 if the Eps termination condition is met</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#applyLearningRateScoreDecay--">applyLearningRateScoreDecay</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="getDefaultConfiguration--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDefaultConfiguration</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a>&nbsp;getDefaultConfiguration()</pre>
</li>
</ul>
<a name="getLabels--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLabels</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;getLabels()</pre>
</li>
</ul>
<a name="getInput--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getInput</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;getInput()</pre>
</li>
</ul>
<a name="setLabels-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLabels</h4>
<pre>public&nbsp;void&nbsp;setLabels(org.nd4j.linalg.api.ndarray.INDArray&nbsp;labels)</pre>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>labels</code> - </dd>
</dl>
</li>
</ul>
<a name="getnLayers--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getnLayers</h4>
<pre>public&nbsp;int&nbsp;getnLayers()</pre>
<div class="block">Get the number of layers in the network</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the number of layers in the network</dd>
</dl>
</li>
</ul>
<a name="getLayers--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLayers</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>[]&nbsp;getLayers()</pre>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="getLayer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLayer</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&nbsp;getLayer(int&nbsp;i)</pre>
</li>
</ul>
<a name="getLayer-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLayer</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&nbsp;getLayer(java.lang.String&nbsp;name)</pre>
</li>
</ul>
<a name="getLayerNames--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLayerNames</h4>
<pre>public&nbsp;java.util.List&lt;java.lang.String&gt;&nbsp;getLayerNames()</pre>
</li>
</ul>
<a name="setLayers-org.deeplearning4j.nn.api.Layer:A-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLayers</h4>
<pre>public&nbsp;void&nbsp;setLayers(<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>[]&nbsp;layers)</pre>
</li>
</ul>
<a name="getMask--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getMask</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;getMask()</pre>
</li>
</ul>
<a name="setMask-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setMask</h4>
<pre>public&nbsp;void&nbsp;setMask(org.nd4j.linalg.api.ndarray.INDArray&nbsp;mask)</pre>
</li>
</ul>
<a name="getMaskArray--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getMaskArray</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;getMaskArray()</pre>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getMaskArray--">getMaskArray</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="isPretrainLayer--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isPretrainLayer</h4>
<pre>public&nbsp;boolean&nbsp;isPretrainLayer()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#isPretrainLayer--">Layer</a></code></span></div>
<div class="block">Returns true if the layer can be trained in an unsupervised/pretrain manner (VAE, RBMs etc)</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#isPretrainLayer--">isPretrainLayer</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>true if the layer can be pretrained (using fit(INDArray), false otherwise</dd>
</dl>
</li>
</ul>
<a name="feedForwardMaskArray-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.MaskState-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForwardMaskArray</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;org.nd4j.linalg.api.ndarray.INDArray,<a href="../../../../org/deeplearning4j/nn/api/MaskState.html" title="enum in org.deeplearning4j.nn.api">MaskState</a>&gt;&nbsp;feedForwardMaskArray(org.nd4j.linalg.api.ndarray.INDArray&nbsp;maskArray,
                                                                                 <a href="../../../../org/deeplearning4j/nn/api/MaskState.html" title="enum in org.deeplearning4j.nn.api">MaskState</a>&nbsp;currentMaskState,
                                                                                 int&nbsp;minibatchSize)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#feedForwardMaskArray-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.MaskState-int-">Layer</a></code></span></div>
<div class="block">Feed forward the input mask array, setting in in the layer as appropriate. This allows different layers to
 handle masks differently - for example, bidirectional RNNs and normal RNNs operate differently with masks (the
 former sets activations to 0 outside of the data present region (and keeps the mask active for future layers like
 dense layers), whereas normal RNNs don't zero out the activations/errors )instead relying on backpropagated error
 arrays to handle the variable length case.<br>
 This is also used for example for networks that contain global pooling layers, arbitrary preprocessors, etc.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#feedForwardMaskArray-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.MaskState-int-">feedForwardMaskArray</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>maskArray</code> - Mask array to set</dd>
<dd><code>currentMaskState</code> - Current state of the mask - see <a href="../../../../org/deeplearning4j/nn/api/MaskState.html" title="enum in org.deeplearning4j.nn.api"><code>MaskState</code></a></dd>
<dd><code>minibatchSize</code> - Current minibatch size. Needs to be known as it cannot always be inferred from the activations
                         array due to reshaping (such as a DenseLayer within a recurrent neural network)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>New mask array after this layer, along with the new mask state.</dd>
</dl>
</li>
</ul>
<a name="error-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>error</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;error(org.nd4j.linalg.api.ndarray.INDArray&nbsp;errorSignal)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#error-org.nd4j.linalg.api.ndarray.INDArray-">Layer</a></code></span></div>
<div class="block">Calculate error with respect to the
 current layer.

 This gradient will contain the error signal</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#error-org.nd4j.linalg.api.ndarray.INDArray-">error</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>errorSignal</code> - the gradient for the forward layer
              If this is the final layer, it will start
              with the error from the output.
              This is on the user to initialize.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the gradient wrt the parameters
 on the current layer</dd>
</dl>
</li>
</ul>
<a name="type--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>type</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.Type.html" title="enum in org.deeplearning4j.nn.api">Layer.Type</a>&nbsp;type()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#type--">Layer</a></code></span></div>
<div class="block">Returns the layer type</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#type--">type</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="derivativeActivation-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>derivativeActivation</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;derivativeActivation(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#derivativeActivation-org.nd4j.linalg.api.ndarray.INDArray-">Layer</a></code></span></div>
<div class="block">Take the derivative of the given input
 based on the activation</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#derivativeActivation-org.nd4j.linalg.api.ndarray.INDArray-">derivativeActivation</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input to take the derivative of</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the derivative of the action</dd>
</dl>
</li>
</ul>
<a name="calcGradient-org.deeplearning4j.nn.gradient.Gradient-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calcGradient</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;calcGradient(<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;layerError,
                             org.nd4j.linalg.api.ndarray.INDArray&nbsp;activation)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#calcGradient-org.deeplearning4j.nn.gradient.Gradient-org.nd4j.linalg.api.ndarray.INDArray-">Layer</a></code></span></div>
<div class="block">Calculate the gradient</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#calcGradient-org.deeplearning4j.nn.gradient.Gradient-org.nd4j.linalg.api.ndarray.INDArray-">calcGradient</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layerError</code> - the layer error</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the gradient</dd>
</dl>
</li>
</ul>
<a name="preOutput-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>preOutput</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;preOutput(org.nd4j.linalg.api.ndarray.INDArray&nbsp;x)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#preOutput-org.nd4j.linalg.api.ndarray.INDArray-">Layer</a></code></span></div>
<div class="block">Raw activations</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#preOutput-org.nd4j.linalg.api.ndarray.INDArray-">preOutput</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>x</code> - the input to transform</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the raw activation
 for this layer</dd>
</dl>
</li>
</ul>
<a name="preOutput-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>preOutput</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;preOutput(org.nd4j.linalg.api.ndarray.INDArray&nbsp;x,
                                                      <a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#preOutput-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">Layer</a></code></span></div>
<div class="block">Raw activations</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#preOutput-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">preOutput</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>x</code> - the input to transform</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the raw activation
 for this layer</dd>
</dl>
</li>
</ul>
<a name="activate-org.deeplearning4j.nn.api.Layer.TrainingMode-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;activate(<a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate-org.deeplearning4j.nn.api.Layer.TrainingMode-">Layer</a></code></span></div>
<div class="block">Trigger an activation with the last specified input</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate-org.deeplearning4j.nn.api.Layer.TrainingMode-">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>training</code> - training or test mode</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the activation of the last specified input</dd>
</dl>
</li>
</ul>
<a name="activate-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;activate(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
                                                     <a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">Layer</a></code></span></div>
<div class="block">Initialize the layer with the given input
 and return the activation for this layer
 given this input</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input to use</dd>
<dd><code>training</code> - train or test mode</dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="transpose--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>transpose</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&nbsp;transpose()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#transpose--">Layer</a></code></span></div>
<div class="block">Return a transposed copy of the weights/bias
 (this means reverse the number of inputs and outputs on the weights)</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#transpose--">transpose</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the transposed layer</dd>
</dl>
</li>
</ul>
<a name="backpropGradient-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>backpropGradient</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;backpropGradient(org.nd4j.linalg.api.ndarray.INDArray&nbsp;epsilon)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#backpropGradient-org.nd4j.linalg.api.ndarray.INDArray-">Layer</a></code></span></div>
<div class="block">Calculate the gradient relative to the error in the next layer</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#backpropGradient-org.nd4j.linalg.api.ndarray.INDArray-">backpropGradient</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>epsilon</code> - w^(L+1)*delta^(L+1). Or, equiv: dC/da, i.e., (dC/dz)*(dz/da) = dC/da, where C 
        is cost function a=sigma(z) is activation.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Pair<Gradient,INDArray> where Gradient is gradient for this layer, INDArray is epsilon needed by next
  layer, but before element-wise multiply by sigmaPrime(z). So for standard feed-forward layer, if this layer is
  L, then return.getSecond() == (w^(L)*(delta^(L))^T)^T</dd>
</dl>
</li>
</ul>
<a name="setIndex-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setIndex</h4>
<pre>public&nbsp;void&nbsp;setIndex(int&nbsp;index)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setIndex-int-">Layer</a></code></span></div>
<div class="block">Set the layer index.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setIndex-int-">setIndex</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="getIndex--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getIndex</h4>
<pre>public&nbsp;int&nbsp;getIndex()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getIndex--">Layer</a></code></span></div>
<div class="block">Get the layer index.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getIndex--">getIndex</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="calcL2-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calcL2</h4>
<pre>public&nbsp;double&nbsp;calcL2(boolean&nbsp;backpropParamsOnly)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#calcL2-boolean-">Layer</a></code></span></div>
<div class="block">Calculate the l2 regularization term<br>
 0.0 if regularization is not used. Or 0.5 * l2Coeff * l2Magnitude otherwise.<br>
 Note that this does not divide by mini-batch size</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#calcL2-boolean-">calcL2</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>backpropParamsOnly</code> - If true: calculate L2 based on backprop params only. If false: calculate
                           based on all params (including pretrain params, if any)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the l2 regularization term for this layer.</dd>
</dl>
</li>
</ul>
<a name="calcL1-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calcL1</h4>
<pre>public&nbsp;double&nbsp;calcL1(boolean&nbsp;backpropParamsOnly)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#calcL1-boolean-">Layer</a></code></span></div>
<div class="block">Calculate the l1 regularization term<br>
 0.0 if regularization is not used. Or l1Coeff * l1Magnitude otherwise.<br>
 Note that this does not divide by mini-batch size</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#calcL1-boolean-">calcL1</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>backpropParamsOnly</code> - If true: calculate L1 based on backprop params only. If false: calculate
                           based on all params (including pretrain params, if any)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the l1 regularization term for this layer.</dd>
</dl>
</li>
</ul>
<a name="update-org.deeplearning4j.nn.gradient.Gradient-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>update</h4>
<pre>public&nbsp;void&nbsp;update(<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;gradient)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#update-org.deeplearning4j.nn.gradient.Gradient-">Model</a></code></span></div>
<div class="block">Update layer weights and biases with gradient change</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#update-org.deeplearning4j.nn.gradient.Gradient-">update</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="preOutput-org.nd4j.linalg.api.ndarray.INDArray-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>preOutput</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;preOutput(org.nd4j.linalg.api.ndarray.INDArray&nbsp;x,
                                                      boolean&nbsp;training)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#preOutput-org.nd4j.linalg.api.ndarray.INDArray-boolean-">Layer</a></code></span></div>
<div class="block">Raw activations</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#preOutput-org.nd4j.linalg.api.ndarray.INDArray-boolean-">preOutput</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>x</code> - the input to transform</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the raw activation
 for this layer</dd>
</dl>
</li>
</ul>
<a name="activate-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;activate(boolean&nbsp;training)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate-boolean-">Layer</a></code></span></div>
<div class="block">Trigger an activation with the last specified input</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate-boolean-">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>training</code> - training or test mode</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the activation of the last specified input</dd>
</dl>
</li>
</ul>
<a name="activate-org.nd4j.linalg.api.ndarray.INDArray-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;activate(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
                                                     boolean&nbsp;training)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate-org.nd4j.linalg.api.ndarray.INDArray-boolean-">Layer</a></code></span></div>
<div class="block">Initialize the layer with the given input
 and return the activation for this layer
 given this input</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate-org.nd4j.linalg.api.ndarray.INDArray-boolean-">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input to use</dd>
<dd><code>training</code> - train or test mode</dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="setInputMiniBatchSize-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setInputMiniBatchSize</h4>
<pre>public&nbsp;void&nbsp;setInputMiniBatchSize(int&nbsp;size)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setInputMiniBatchSize-int-">Layer</a></code></span></div>
<div class="block">Set current/last input mini-batch size.<br>
 Used for score and gradient calculations. Mini batch size may be different from
 getInput().size(0) due to reshaping operations - for example, when using RNNs with
 DenseLayer and OutputLayer. Called automatically during forward pass.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setInputMiniBatchSize-int-">setInputMiniBatchSize</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="getInputMiniBatchSize--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getInputMiniBatchSize</h4>
<pre>public&nbsp;int&nbsp;getInputMiniBatchSize()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getInputMiniBatchSize--">Layer</a></code></span></div>
<div class="block">Get current/last input mini-batch size, as set by setInputMiniBatchSize(int)</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getInputMiniBatchSize--">getInputMiniBatchSize</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setInputMiniBatchSize-int-"><code>Layer.setInputMiniBatchSize(int)</code></a></dd>
</dl>
</li>
</ul>
<a name="setMaskArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setMaskArray</h4>
<pre>public&nbsp;void&nbsp;setMaskArray(org.nd4j.linalg.api.ndarray.INDArray&nbsp;maskArray)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setMaskArray-org.nd4j.linalg.api.ndarray.INDArray-">Layer</a></code></span></div>
<div class="block">Set the mask array. Note: In general, <a href="../../../../org/deeplearning4j/nn/api/Layer.html#feedForwardMaskArray-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.MaskState-int-"><code>Layer.feedForwardMaskArray(INDArray, MaskState, int)</code></a> should be used in
 preference to this.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setMaskArray-org.nd4j.linalg.api.ndarray.INDArray-">setMaskArray</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>maskArray</code> - Mask array to set</dd>
</dl>
</li>
</ul>
<a name="rnnTimeStep-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rnnTimeStep</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;rnnTimeStep(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</pre>
<div class="block">If this MultiLayerNetwork contains one or more RNN layers: conduct forward pass (prediction)
 but using previous stored state for any RNN layers. The activations for the final step are
 also stored in the RNN layers for use next time rnnTimeStep() is called.<br>
 This method can be used to generate output one or more steps at a time instead of always having to do
 forward pass from t=0. Example uses are for streaming data, and for generating samples from network output
 one step at a time (where samples are then fed back into the network as input)<br>
 If no previous state is present in RNN layers (i.e., initially or after calling rnnClearPreviousState()),
 the default initialization (usually 0) is used.<br>
 Supports mini-batch (i.e., multiple predictions/forward pass in parallel) as well as for single examples.<br></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - Input to network. May be for one or multiple time steps. For single time step:
  input has shape [miniBatchSize,inputSize] or [miniBatchSize,inputSize,1]. miniBatchSize=1 for single example.<br>
  For multiple time steps: [miniBatchSize,inputSize,inputTimeSeriesLength]</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Output activations. If output is RNN layer (such as RnnOutputLayer): if input has shape [miniBatchSize,inputSize]
 i.e., is 2d, output has shape [miniBatchSize,outputSize] (i.e., also 2d).<br>
 Otherwise output is 3d [miniBatchSize,outputSize,inputTimeSeriesLength] when using RnnOutputLayer.</dd>
</dl>
</li>
</ul>
<a name="rnnGetPreviousState-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rnnGetPreviousState</h4>
<pre>public&nbsp;java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;rnnGetPreviousState(int&nbsp;layer)</pre>
<div class="block">Get the state of the RNN layer, as used in rnnTimeStep().</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layer</code> - Number/index of the layer.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Hidden state, or null if layer is not an RNN layer</dd>
</dl>
</li>
</ul>
<a name="rnnSetPreviousState-int-java.util.Map-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rnnSetPreviousState</h4>
<pre>public&nbsp;void&nbsp;rnnSetPreviousState(int&nbsp;layer,
                                java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;state)</pre>
<div class="block">Set the state of the RNN layer.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layer</code> - The number/index of the layer.</dd>
<dd><code>state</code> - The state to set the specified layer to</dd>
</dl>
</li>
</ul>
<a name="rnnClearPreviousState--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rnnClearPreviousState</h4>
<pre>public&nbsp;void&nbsp;rnnClearPreviousState()</pre>
<div class="block">Clear the previous state of the RNN layers (if any).</div>
</li>
</ul>
<a name="rnnActivateUsingStoredState-org.nd4j.linalg.api.ndarray.INDArray-boolean-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rnnActivateUsingStoredState</h4>
<pre>public&nbsp;java.util.List&lt;org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;rnnActivateUsingStoredState(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
                                                                                        boolean&nbsp;training,
                                                                                        boolean&nbsp;storeLastForTBPTT)</pre>
<div class="block">Similar to rnnTimeStep and feedForward() methods. Difference here is that this method:<br>
 (a) like rnnTimeStep does forward pass using stored state for RNN layers, and<br>
 (b) unlike rnnTimeStep does not modify the RNN layer state<br>
 Therefore multiple calls to this method with the same input should have the same output.<br>
 Typically used during training only. Use rnnTimeStep for prediction/forward pass at test time.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - Input to network</dd>
<dd><code>training</code> - Whether training or not</dd>
<dd><code>storeLastForTBPTT</code> - set to true if used as part of truncated BPTT training</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Activations for each layer (including input, as per feedforward() etc)</dd>
</dl>
</li>
</ul>
<a name="getUpdater--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getUpdater</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Updater.html" title="interface in org.deeplearning4j.nn.api">Updater</a>&nbsp;getUpdater()</pre>
<div class="block">Get the updater for this MultiLayerNetwork</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Updater for MultiLayerNetwork</dd>
</dl>
</li>
</ul>
<a name="setUpdater-org.deeplearning4j.nn.api.Updater-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setUpdater</h4>
<pre>public&nbsp;void&nbsp;setUpdater(<a href="../../../../org/deeplearning4j/nn/api/Updater.html" title="interface in org.deeplearning4j.nn.api">Updater</a>&nbsp;updater)</pre>
<div class="block">Set the updater for the MultiLayerNetwork</div>
</li>
</ul>
<a name="setLayerMaskArrays-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLayerMaskArrays</h4>
<pre>public&nbsp;void&nbsp;setLayerMaskArrays(org.nd4j.linalg.api.ndarray.INDArray&nbsp;featuresMaskArray,
                               org.nd4j.linalg.api.ndarray.INDArray&nbsp;labelsMaskArray)</pre>
<div class="block">Set the mask arrays for features and labels. Mask arrays are typically used in situations such as one-to-many
 and many-to-one learning with recurrent neural networks, as well as for supporting time series of varying lengths
 within the same minibatch.<br>
 For example, with RNN data sets with input of shape [miniBatchSize,nIn,timeSeriesLength] and outputs of shape
 [miniBatchSize,nOut,timeSeriesLength], the features and mask arrays will have shape [miniBatchSize,timeSeriesLength]
 and contain values 0 or 1 at each element (to specify whether a given input/example is present - or merely padding -
 at a given time step).<br>
 <b>NOTE</b>: This method is not usually used directly. Instead, methods such as <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForward-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-"><code>feedForward(INDArray, INDArray, INDArray)</code></a>
 and <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output-org.nd4j.linalg.api.ndarray.INDArray-boolean-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-"><code>output(INDArray, boolean, INDArray, INDArray)</code></a> handle setting of masking internally.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>featuresMaskArray</code> - Mask array for features (input)</dd>
<dd><code>labelsMaskArray</code> - Mask array for labels (output)</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#clearLayerMaskArrays--"><code>clearLayerMaskArrays()</code></a></dd>
</dl>
</li>
</ul>
<a name="clearLayerMaskArrays--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clearLayerMaskArrays</h4>
<pre>public&nbsp;void&nbsp;clearLayerMaskArrays()</pre>
<div class="block">Remove the mask arrays from all layers.<br>
 See <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLayerMaskArrays-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-"><code>setLayerMaskArrays(INDArray, INDArray)</code></a> for details on mask arrays.</div>
</li>
</ul>
<a name="evaluate-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evaluate</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/eval/Evaluation.html" title="class in org.deeplearning4j.eval">Evaluation</a>&nbsp;evaluate(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator)</pre>
<div class="block">Evaluate the network (classification performance)</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Iterator to evaluate on</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Evaluation object; results of evaluation on all examples in the data set</dd>
</dl>
</li>
</ul>
<a name="evaluateRegression-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evaluateRegression</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/eval/RegressionEvaluation.html" title="class in org.deeplearning4j.eval">RegressionEvaluation</a>&nbsp;evaluateRegression(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator)</pre>
<div class="block">Evaluate the network for regression performance</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Data to evaluate on</dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="evaluateROC-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evaluateROC</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/eval/ROC.html" title="class in org.deeplearning4j.eval">ROC</a>&nbsp;evaluateROC(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator,
                       int&nbsp;rocThresholdSteps)</pre>
<div class="block">Evaluate the network (must be a binary classifier) on the specified data, using the <a href="../../../../org/deeplearning4j/eval/ROC.html" title="class in org.deeplearning4j.eval"><code>ROC</code></a> class</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Data to evaluate on</dd>
<dd><code>rocThresholdSteps</code> - Number of threshold steps to use with <a href="../../../../org/deeplearning4j/eval/ROC.html" title="class in org.deeplearning4j.eval"><code>ROC</code></a></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>ROC evaluation on the given dataset</dd>
</dl>
</li>
</ul>
<a name="evaluateROCMultiClass-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evaluateROCMultiClass</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/eval/ROCMultiClass.html" title="class in org.deeplearning4j.eval">ROCMultiClass</a>&nbsp;evaluateROCMultiClass(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator,
                                           int&nbsp;rocThresholdSteps)</pre>
<div class="block">Evaluate the network on the specified data, using the <a href="../../../../org/deeplearning4j/eval/ROCMultiClass.html" title="class in org.deeplearning4j.eval"><code>ROCMultiClass</code></a> class</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Data to evaluate on</dd>
<dd><code>rocThresholdSteps</code> - Number of threshold steps to use with <a href="../../../../org/deeplearning4j/eval/ROCMultiClass.html" title="class in org.deeplearning4j.eval"><code>ROCMultiClass</code></a></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Multi-class ROC evaluation on the given dataset</dd>
</dl>
</li>
</ul>
<a name="doEvaluation-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-org.deeplearning4j.eval.IEvaluation-">
<!--   -->
</a><a name="doEvaluation-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-T-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>doEvaluation</h4>
<pre>public&nbsp;&lt;T extends <a href="../../../../org/deeplearning4j/eval/IEvaluation.html" title="interface in org.deeplearning4j.eval">IEvaluation</a>&gt;&nbsp;T&nbsp;doEvaluation(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator,
                                              T&nbsp;evaluation)</pre>
<div class="block">Perform evaluation using an arbitrary IEvaluation instance.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - data to evaluate on</dd>
<dd><code>evaluation</code> - IEvaluation instance to perform evaluation with</dd>
</dl>
</li>
</ul>
<a name="evaluate-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-java.util.List-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evaluate</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/eval/Evaluation.html" title="class in org.deeplearning4j.eval">Evaluation</a>&nbsp;evaluate(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator,
                           java.util.List&lt;java.lang.String&gt;&nbsp;labelsList)</pre>
<div class="block">Evaluate the network on the provided data set. Used for evaluating the performance of classifiers</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Data to undertake evaluation on</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Evaluation object, summarizing the results of the evaluation on the provided DataSetIterator</dd>
</dl>
</li>
</ul>
<a name="evaluate-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-java.util.List-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evaluate</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/eval/Evaluation.html" title="class in org.deeplearning4j.eval">Evaluation</a>&nbsp;evaluate(org.nd4j.linalg.dataset.api.iterator.DataSetIterator&nbsp;iterator,
                           java.util.List&lt;java.lang.String&gt;&nbsp;labelsList,
                           int&nbsp;topN)</pre>
<div class="block">Evaluate the network (for classification) on the provided data set, with top N accuracy in addition to standard accuracy.
 For 'standard' accuracy evaluation only, use topN = 1</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Iterator (data) to evaluate on</dd>
<dd><code>labelsList</code> - List of labels. May be null.</dd>
<dd><code>topN</code> - N value for top N accuracy evaluation</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Evaluation object, summarizing the results of the evaluation on the provided DataSetIterator</dd>
</dl>
</li>
</ul>
<a name="summary--">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>summary</h4>
<pre>public&nbsp;java.lang.String&nbsp;summary()</pre>
<div class="block">String detailing the architecture of the multilayernetwork.
 Columns are LayerIndex with layer type, nIn, nOut, Total number of parameters and the Shapes of the parameters
 Will also give information about frozen layers, if any.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Summary as a string</dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../../org/deeplearning4j/nn/multilayer/GravesLSTMOutputTest.html" title="class in org.deeplearning4j.nn.multilayer"><span class="typeNameLink">Prev&nbsp;Class</span></a></li>
<li><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerTest.html" title="class in org.deeplearning4j.nn.multilayer"><span class="typeNameLink">Next&nbsp;Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" target="_top">Frames</a></li>
<li><a href="MultiLayerNetwork.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field.summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field.detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
