<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_51) on Thu Mar 02 23:40:03 PST 2017 -->
<title>VariationalAutoencoder</title>
<meta name="date" content="2017-03-02">
<link rel="stylesheet" type="text/css" href="../../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="VariationalAutoencoder";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":10,"i1":10,"i2":10,"i3":10,"i4":10,"i5":10,"i6":10,"i7":10,"i8":10,"i9":10,"i10":10,"i11":10,"i12":10,"i13":10,"i14":10,"i15":10,"i16":10,"i17":10,"i18":10,"i19":10,"i20":10,"i21":10,"i22":10,"i23":10,"i24":10,"i25":10,"i26":10,"i27":10,"i28":10,"i29":10,"i30":10,"i31":10,"i32":10,"i33":10,"i34":10,"i35":10,"i36":10,"i37":10,"i38":10,"i39":10,"i40":10,"i41":10,"i42":10,"i43":10,"i44":10,"i45":10,"i46":10,"i47":10,"i48":10,"i49":10,"i50":10,"i51":10,"i52":10,"i53":10,"i54":10,"i55":10,"i56":10,"i57":10,"i58":10,"i59":10,"i60":10,"i61":10,"i62":10,"i63":10,"i64":10,"i65":10,"i66":10,"i67":10,"i68":10,"i69":10};
var tabs = {65535:["t0","All Methods"],2:["t2","Instance Methods"],8:["t4","Concrete Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev&nbsp;Class</li>
<li>Next&nbsp;Class</li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html" target="_top">Frames</a></li>
<li><a href="VariationalAutoencoder.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field.summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field.detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.deeplearning4j.nn.layers.variational</div>
<h2 title="Class VariationalAutoencoder" class="title">Class VariationalAutoencoder</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li>org.deeplearning4j.nn.layers.variational.VariationalAutoencoder</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, java.lang.Cloneable, <a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>, <a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="typeNameLabel">VariationalAutoencoder</span>
extends java.lang.Object
implements <a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></pre>
<div class="block">Variational Autoencoder layer
 <p>
 See: Kingma & Welling, 2013: Auto-Encoding Variational Bayes - https://arxiv.org/abs/1312.6114
 <p>
 This implementation allows multiple encoder and decoder layers, the number and sizes of which can be set independently.
 <p>
 A note on scores during pretraining: This implementation minimizes the negative of the variational lower bound objective
 as described in Kingma & Welling; the mathematics in that paper is based on maximization of the variational lower bound instead.
 Thus, scores reported during pretraining in DL4J are the negative of the variational lower bound equation in the paper.
 The backpropagation and learning procedure is otherwise as described there.</div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../../serialized-form.html#org.deeplearning4j.nn.layers.variational.VariationalAutoencoder">Serialized Form</a></dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested.class.summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<ul class="blockList">
<li class="blockList"><a name="nested.classes.inherited.from.class.org.deeplearning4j.nn.api.Layer">
<!--   -->
</a>
<h3>Nested classes/interfaces inherited from interface&nbsp;org.deeplearning4j.nn.api.<a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></h3>
<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>, <a href="../../../../../org/deeplearning4j/nn/api/Layer.Type.html" title="enum in org.deeplearning4j.nn.api">Layer.Type</a></code></li>
</ul>
</li>
</ul>
<!-- =========== FIELD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="field.summary">
<!--   -->
</a>
<h3>Field Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Field Summary table, listing fields, and an explanation">
<caption><span>Fields</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Field and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#conf">conf</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected int[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#decoderLayerSizes">decoderLayerSizes</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected int[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#encoderLayerSizes">encoderLayerSizes</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#gradient">gradient</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#gradientsFlattened">gradientsFlattened</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#gradientViews">gradientViews</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#index">index</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#input">input</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected java.util.Collection&lt;<a href="../../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#iterationListeners">iterationListeners</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#maskArray">maskArray</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#numSamples">numSamples</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../../org/deeplearning4j/optimize/api/ConvexOptimizer.html" title="interface in org.deeplearning4j.optimize.api">ConvexOptimizer</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#optimizer">optimizer</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#params">params</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#paramsFlattened">paramsFlattened</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected org.nd4j.linalg.activations.IActivation</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#pzxActivationFn">pzxActivationFn</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../../org/deeplearning4j/nn/conf/layers/variational/ReconstructionDistribution.html" title="interface in org.deeplearning4j.nn.conf.layers.variational">ReconstructionDistribution</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#reconstructionDistribution">reconstructionDistribution</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#score">score</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../../org/deeplearning4j/optimize/Solver.html" title="class in org.deeplearning4j.optimize">Solver</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#solver">solver</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected java.util.Collection&lt;<a href="../../../../../org/deeplearning4j/optimize/api/TrainingListener.html" title="interface in org.deeplearning4j.optimize.api">TrainingListener</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#trainingListeners">trainingListeners</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#zeroedPretrainParamGradients">zeroedPretrainParamGradients</a></span></code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#VariationalAutoencoder-org.deeplearning4j.nn.conf.NeuralNetConfiguration-">VariationalAutoencoder</a></span>(<a href="../../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a>&nbsp;conf)</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">Instance Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#accumulateScore-double-">accumulateScore</a></span>(double&nbsp;accum)</code>
<div class="block">Sets a rolling tally for the score.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#activate--">activate</a></span>()</code>
<div class="block">Trigger an activation with the last specified input</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#activate-boolean-">activate</a></span>(boolean&nbsp;training)</code>
<div class="block">Trigger an activation with the last specified input</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#activate-org.nd4j.linalg.api.ndarray.INDArray-">activate</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</code>
<div class="block">Initialize the layer with the given input
 and return the activation for this layer
 given this input</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#activate-org.nd4j.linalg.api.ndarray.INDArray-boolean-">activate</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
        boolean&nbsp;training)</code>
<div class="block">Initialize the layer with the given input
 and return the activation for this layer
 given this input</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#activate-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">activate</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
        <a href="../../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</code>
<div class="block">Initialize the layer with the given input
 and return the activation for this layer
 given this input</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#activate-org.deeplearning4j.nn.api.Layer.TrainingMode-">activate</a></span>(<a href="../../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</code>
<div class="block">Trigger an activation with the last specified input</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#activationMean--">activationMean</a></span>()</code>
<div class="block">Calculate the mean representation
 for the activation for this layer</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#applyLearningRateScoreDecay--">applyLearningRateScoreDecay</a></span>()</code>
<div class="block">Update learningRate using for this model.</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;<a href="../../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#backpropGradient-org.nd4j.linalg.api.ndarray.INDArray-">backpropGradient</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;epsilon)</code>
<div class="block">Calculate the gradient relative to the error in the next layer</div>
</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#batchSize--">batchSize</a></span>()</code>
<div class="block">The current inputs batch size</div>
</td>
</tr>
<tr id="i11" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#calcGradient-org.deeplearning4j.nn.gradient.Gradient-org.nd4j.linalg.api.ndarray.INDArray-">calcGradient</a></span>(<a href="../../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;layerError,
            org.nd4j.linalg.api.ndarray.INDArray&nbsp;indArray)</code>
<div class="block">Calculate the gradient</div>
</td>
</tr>
<tr id="i12" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#calcL1-boolean-">calcL1</a></span>(boolean&nbsp;backpropParamsOnly)</code>
<div class="block">Calculate the l1 regularization term<br>
 0.0 if regularization is not used.</div>
</td>
</tr>
<tr id="i13" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#calcL2-boolean-">calcL2</a></span>(boolean&nbsp;backpropParamsOnly)</code>
<div class="block">Calculate the l2 regularization term<br>
 0.0 if regularization is not used.</div>
</td>
</tr>
<tr id="i14" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#clear--">clear</a></span>()</code>
<div class="block">Clear input</div>
</td>
</tr>
<tr id="i15" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#clone--">clone</a></span>()</code>
<div class="block">Clone the layer</div>
</td>
</tr>
<tr id="i16" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#computeGradientAndScore--">computeGradientAndScore</a></span>()</code>
<div class="block">Update the score</div>
</td>
</tr>
<tr id="i17" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#conf--">conf</a></span>()</code>
<div class="block">The configuration for the neural network</div>
</td>
</tr>
<tr id="i18" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#derivativeActivation-org.nd4j.linalg.api.ndarray.INDArray-">derivativeActivation</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</code>
<div class="block">Take the derivative of the given input
 based on the activation</div>
</td>
</tr>
<tr id="i19" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#error-org.nd4j.linalg.api.ndarray.INDArray-">error</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</code>
<div class="block">Calculate error with respect to the
 current layer.</div>
</td>
</tr>
<tr id="i20" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;org.nd4j.linalg.api.ndarray.INDArray,<a href="../../../../../org/deeplearning4j/nn/api/MaskState.html" title="enum in org.deeplearning4j.nn.api">MaskState</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#feedForwardMaskArray-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.MaskState-int-">feedForwardMaskArray</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;maskArray,
                    <a href="../../../../../org/deeplearning4j/nn/api/MaskState.html" title="enum in org.deeplearning4j.nn.api">MaskState</a>&nbsp;currentMaskState,
                    int&nbsp;minibatchSize)</code>
<div class="block">Feed forward the input mask array, setting in in the layer as appropriate.</div>
</td>
</tr>
<tr id="i21" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#fit--">fit</a></span>()</code>
<div class="block">All models have a fit method</div>
</td>
</tr>
<tr id="i22" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#fit-org.nd4j.linalg.api.ndarray.INDArray-">fit</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;data)</code>
<div class="block">Fit the model to the given data</div>
</td>
</tr>
<tr id="i23" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#generateAtMeanGivenZ-org.nd4j.linalg.api.ndarray.INDArray-">generateAtMeanGivenZ</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;latentSpaceValues)</code>
<div class="block">Given a specified values for the latent space as input (latent space being z in p(z|data)), generate output
 from P(x|z), where x = E[P(x|z)]<br>
 i.e., return the mean value for the distribution P(x|z)</div>
</td>
</tr>
<tr id="i24" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#generateRandomGivenZ-org.nd4j.linalg.api.ndarray.INDArray-">generateRandomGivenZ</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;latentSpaceValues)</code>
<div class="block">Given a specified values for the latent space as input (latent space being z in p(z|data)), randomly generate output
 x, where x ~ P(x|z)</div>
</td>
</tr>
<tr id="i25" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#getIndex--">getIndex</a></span>()</code>
<div class="block">Get the layer index.</div>
</td>
</tr>
<tr id="i26" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#getInputMiniBatchSize--">getInputMiniBatchSize</a></span>()</code>
<div class="block">Get current/last input mini-batch size, as set by setInputMiniBatchSize(int)</div>
</td>
</tr>
<tr id="i27" class="rowColor">
<td class="colFirst"><code>java.util.Collection&lt;<a href="../../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#getListeners--">getListeners</a></span>()</code>
<div class="block">Get the iteration listeners for this layer.</div>
</td>
</tr>
<tr id="i28" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#getMaskArray--">getMaskArray</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i29" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/deeplearning4j/optimize/api/ConvexOptimizer.html" title="interface in org.deeplearning4j.optimize.api">ConvexOptimizer</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#getOptimizer--">getOptimizer</a></span>()</code>
<div class="block">Returns this models optimizer</div>
</td>
</tr>
<tr id="i30" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#getParam-java.lang.String-">getParam</a></span>(java.lang.String&nbsp;param)</code>
<div class="block">Get the parameter</div>
</td>
</tr>
<tr id="i31" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#gradient--">gradient</a></span>()</code>
<div class="block">Calculate a gradient</div>
</td>
</tr>
<tr id="i32" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;<a href="../../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,java.lang.Double&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#gradientAndScore--">gradientAndScore</a></span>()</code>
<div class="block">Get the gradient and score</div>
</td>
</tr>
<tr id="i33" class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#hasLossFunction--">hasLossFunction</a></span>()</code>
<div class="block">Does the reconstruction distribution have a loss function (such as mean squared error) or is it a standard
 probabilistic reconstruction distribution?</div>
</td>
</tr>
<tr id="i34" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#initParams--">initParams</a></span>()</code>
<div class="block">Initialize the parameters</div>
</td>
</tr>
<tr id="i35" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#input--">input</a></span>()</code>
<div class="block">The input/feature matrix for the model</div>
</td>
</tr>
<tr id="i36" class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#isPretrainLayer--">isPretrainLayer</a></span>()</code>
<div class="block">Returns true if the layer can be trained in an unsupervised/pretrain manner (VAE, RBMs etc)</div>
</td>
</tr>
<tr id="i37" class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#isPretrainParam-java.lang.String-">isPretrainParam</a></span>(java.lang.String&nbsp;param)</code>&nbsp;</td>
</tr>
<tr id="i38" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#iterate-org.nd4j.linalg.api.ndarray.INDArray-">iterate</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</code>
<div class="block">Run one iteration</div>
</td>
</tr>
<tr id="i39" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#merge-org.deeplearning4j.nn.api.Layer-int-">merge</a></span>(<a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&nbsp;layer,
     int&nbsp;batchSize)</code>
<div class="block">Parameter averaging</div>
</td>
</tr>
<tr id="i40" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#numParams--">numParams</a></span>()</code>
<div class="block">the number of parameters for the model</div>
</td>
</tr>
<tr id="i41" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#numParams-boolean-">numParams</a></span>(boolean&nbsp;backwards)</code>
<div class="block">the number of parameters for the model</div>
</td>
</tr>
<tr id="i42" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#params--">params</a></span>()</code>
<div class="block">Parameters of the model (if any)</div>
</td>
</tr>
<tr id="i43" class="rowColor">
<td class="colFirst"><code>java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#paramTable--">paramTable</a></span>()</code>
<div class="block">The param table</div>
</td>
</tr>
<tr id="i44" class="altColor">
<td class="colFirst"><code>java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#paramTable-boolean-">paramTable</a></span>(boolean&nbsp;backpropParamsOnly)</code>
<div class="block">Table of parameters by key, for backprop
 For many models (dense layers, etc) - all parameters are backprop parameters</div>
</td>
</tr>
<tr id="i45" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#preOutput-boolean-">preOutput</a></span>(boolean&nbsp;training)</code>&nbsp;</td>
</tr>
<tr id="i46" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#preOutput-org.nd4j.linalg.api.ndarray.INDArray-">preOutput</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;x)</code>
<div class="block">Raw activations</div>
</td>
</tr>
<tr id="i47" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#preOutput-org.nd4j.linalg.api.ndarray.INDArray-boolean-">preOutput</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;x,
         boolean&nbsp;training)</code>
<div class="block">Raw activations</div>
</td>
</tr>
<tr id="i48" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#preOutput-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">preOutput</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;x,
         <a href="../../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</code>
<div class="block">Raw activations</div>
</td>
</tr>
<tr id="i49" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#reconstructionError-org.nd4j.linalg.api.ndarray.INDArray-">reconstructionError</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;data)</code>
<div class="block">Return the reconstruction error for this variational autoencoder.<br>
 <b>NOTE (important):</b> This method is used ONLY for VAEs that have a standard neural network loss function (i.e.,
 an <code>ILossFunction</code> instance such as mean squared error) instead of using a
 probabilistic reconstruction distribution P(x|z) for the reconstructions (as presented in the VAE architecture by
 Kingma and Welling).<br>
 You can check if the VAE has a loss function using <a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#hasLossFunction--"><code>hasLossFunction()</code></a><br>
 Consequently, the reconstruction error is a simple deterministic function (no Monte-Carlo sampling is required,
 unlike <a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#reconstructionProbability-org.nd4j.linalg.api.ndarray.INDArray-int-"><code>reconstructionProbability(INDArray, int)</code></a> and <a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#reconstructionLogProbability-org.nd4j.linalg.api.ndarray.INDArray-int-"><code>reconstructionLogProbability(INDArray, int)</code></a>)</div>
</td>
</tr>
<tr id="i50" class="altColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#reconstructionLogProbability-org.nd4j.linalg.api.ndarray.INDArray-int-">reconstructionLogProbability</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;data,
                            int&nbsp;numSamples)</code>
<div class="block">Return the log reconstruction probability given the specified number of samples.<br>
 See <a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#reconstructionLogProbability-org.nd4j.linalg.api.ndarray.INDArray-int-"><code>reconstructionLogProbability(INDArray, int)</code></a> for more details</div>
</td>
</tr>
<tr id="i51" class="rowColor">
<td class="colFirst"><code>org.nd4j.linalg.api.ndarray.INDArray</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#reconstructionProbability-org.nd4j.linalg.api.ndarray.INDArray-int-">reconstructionProbability</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;data,
                         int&nbsp;numSamples)</code>
<div class="block">Calculate the reconstruction probability, as described in An & Cho, 2015 - "Variational Autoencoder based
 Anomaly Detection using Reconstruction Probability" (Algorithm 4)<br>
 The authors describe it as follows: "This is essentially the probability of the data being generated from a given
 latent variable drawn from the approximate posterior distribution."<br>
 <br>
 Specifically, for each example x in the input, calculate p(x).</div>
</td>
</tr>
<tr id="i52" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#score--">score</a></span>()</code>
<div class="block">The score for the model</div>
</td>
</tr>
<tr id="i53" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#setBackpropGradientsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">setBackpropGradientsViewArray</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;gradients)</code>
<div class="block">Set the gradients array as a view of the full (backprop) network parameters
 NOTE: this is intended to be used internally in MultiLayerNetwork and ComputationGraph, not by users.</div>
</td>
</tr>
<tr id="i54" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#setConf-org.deeplearning4j.nn.conf.NeuralNetConfiguration-">setConf</a></span>(<a href="../../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a>&nbsp;conf)</code>
<div class="block">Setter for the configuration</div>
</td>
</tr>
<tr id="i55" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#setIndex-int-">setIndex</a></span>(int&nbsp;index)</code>
<div class="block">Set the layer index.</div>
</td>
</tr>
<tr id="i56" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#setInput-org.nd4j.linalg.api.ndarray.INDArray-">setInput</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</code>
<div class="block">Get the layer input.</div>
</td>
</tr>
<tr id="i57" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#setInputMiniBatchSize-int-">setInputMiniBatchSize</a></span>(int&nbsp;size)</code>
<div class="block">Set current/last input mini-batch size.<br>
 Used for score and gradient calculations.</div>
</td>
</tr>
<tr id="i58" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#setListeners-java.util.Collection-">setListeners</a></span>(java.util.Collection&lt;<a href="../../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>&gt;&nbsp;listeners)</code>
<div class="block">Set the iteration listeners for this layer.</div>
</td>
</tr>
<tr id="i59" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#setListeners-org.deeplearning4j.optimize.api.IterationListener...-">setListeners</a></span>(<a href="../../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>...&nbsp;listeners)</code>
<div class="block">Set the iteration listeners for this layer.</div>
</td>
</tr>
<tr id="i60" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#setMaskArray-org.nd4j.linalg.api.ndarray.INDArray-">setMaskArray</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;maskArray)</code>
<div class="block">Set the mask array.</div>
</td>
</tr>
<tr id="i61" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#setParam-java.lang.String-org.nd4j.linalg.api.ndarray.INDArray-">setParam</a></span>(java.lang.String&nbsp;key,
        org.nd4j.linalg.api.ndarray.INDArray&nbsp;val)</code>
<div class="block">Set the parameter with a new ndarray</div>
</td>
</tr>
<tr id="i62" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#setParams-org.nd4j.linalg.api.ndarray.INDArray-">setParams</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;params)</code>
<div class="block">Set the parameters for this model.</div>
</td>
</tr>
<tr id="i63" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#setParamsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">setParamsViewArray</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;params)</code>
<div class="block">Set the initial parameters array as a view of the full (backprop) network parameters
 NOTE: this is intended to be used internally in MultiLayerNetwork and ComputationGraph, not by users.</div>
</td>
</tr>
<tr id="i64" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#setParamTable-java.util.Map-">setParamTable</a></span>(java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;paramTable)</code>
<div class="block">Setter for the param table</div>
</td>
</tr>
<tr id="i65" class="rowColor">
<td class="colFirst"><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#transpose--">transpose</a></span>()</code>
<div class="block">Return a transposed copy of the weights/bias
 (this means reverse the number of inputs and outputs on the weights)</div>
</td>
</tr>
<tr id="i66" class="altColor">
<td class="colFirst"><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.Type.html" title="enum in org.deeplearning4j.nn.api">Layer.Type</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#type--">type</a></span>()</code>
<div class="block">Returns the layer type</div>
</td>
</tr>
<tr id="i67" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#update-org.deeplearning4j.nn.gradient.Gradient-">update</a></span>(<a href="../../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;gradient)</code>
<div class="block">Update layer weights and biases with gradient change</div>
</td>
</tr>
<tr id="i68" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#update-org.nd4j.linalg.api.ndarray.INDArray-java.lang.String-">update</a></span>(org.nd4j.linalg.api.ndarray.INDArray&nbsp;gradient,
      java.lang.String&nbsp;paramType)</code>
<div class="block">Perform one update  applying the gradient</div>
</td>
</tr>
<tr id="i69" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#validateInput--">validateInput</a></span>()</code>
<div class="block">Validate the input</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ FIELD DETAIL =========== -->
<ul class="blockList">
<li class="blockList"><a name="field.detail">
<!--   -->
</a>
<h3>Field Detail</h3>
<a name="input">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>input</h4>
<pre>protected&nbsp;org.nd4j.linalg.api.ndarray.INDArray input</pre>
</li>
</ul>
<a name="paramsFlattened">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>paramsFlattened</h4>
<pre>protected&nbsp;org.nd4j.linalg.api.ndarray.INDArray paramsFlattened</pre>
</li>
</ul>
<a name="gradientsFlattened">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>gradientsFlattened</h4>
<pre>protected&nbsp;org.nd4j.linalg.api.ndarray.INDArray gradientsFlattened</pre>
</li>
</ul>
<a name="params">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>params</h4>
<pre>protected&nbsp;java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt; params</pre>
</li>
</ul>
<a name="gradientViews">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>gradientViews</h4>
<pre>protected transient&nbsp;java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt; gradientViews</pre>
</li>
</ul>
<a name="conf">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>conf</h4>
<pre>protected&nbsp;<a href="../../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a> conf</pre>
</li>
</ul>
<a name="score">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>score</h4>
<pre>protected&nbsp;double score</pre>
</li>
</ul>
<a name="optimizer">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>optimizer</h4>
<pre>protected&nbsp;<a href="../../../../../org/deeplearning4j/optimize/api/ConvexOptimizer.html" title="interface in org.deeplearning4j.optimize.api">ConvexOptimizer</a> optimizer</pre>
</li>
</ul>
<a name="gradient">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>gradient</h4>
<pre>protected&nbsp;<a href="../../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a> gradient</pre>
</li>
</ul>
<a name="iterationListeners">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>iterationListeners</h4>
<pre>protected&nbsp;java.util.Collection&lt;<a href="../../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>&gt; iterationListeners</pre>
</li>
</ul>
<a name="trainingListeners">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>trainingListeners</h4>
<pre>protected&nbsp;java.util.Collection&lt;<a href="../../../../../org/deeplearning4j/optimize/api/TrainingListener.html" title="interface in org.deeplearning4j.optimize.api">TrainingListener</a>&gt; trainingListeners</pre>
</li>
</ul>
<a name="index">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>index</h4>
<pre>protected&nbsp;int index</pre>
</li>
</ul>
<a name="maskArray">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>maskArray</h4>
<pre>protected&nbsp;org.nd4j.linalg.api.ndarray.INDArray maskArray</pre>
</li>
</ul>
<a name="solver">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>solver</h4>
<pre>protected&nbsp;<a href="../../../../../org/deeplearning4j/optimize/Solver.html" title="class in org.deeplearning4j.optimize">Solver</a> solver</pre>
</li>
</ul>
<a name="encoderLayerSizes">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>encoderLayerSizes</h4>
<pre>protected&nbsp;int[] encoderLayerSizes</pre>
</li>
</ul>
<a name="decoderLayerSizes">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>decoderLayerSizes</h4>
<pre>protected&nbsp;int[] decoderLayerSizes</pre>
</li>
</ul>
<a name="reconstructionDistribution">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reconstructionDistribution</h4>
<pre>protected&nbsp;<a href="../../../../../org/deeplearning4j/nn/conf/layers/variational/ReconstructionDistribution.html" title="interface in org.deeplearning4j.nn.conf.layers.variational">ReconstructionDistribution</a> reconstructionDistribution</pre>
</li>
</ul>
<a name="pzxActivationFn">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pzxActivationFn</h4>
<pre>protected&nbsp;org.nd4j.linalg.activations.IActivation pzxActivationFn</pre>
</li>
</ul>
<a name="numSamples">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numSamples</h4>
<pre>protected&nbsp;int numSamples</pre>
</li>
</ul>
<a name="zeroedPretrainParamGradients">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>zeroedPretrainParamGradients</h4>
<pre>protected&nbsp;boolean zeroedPretrainParamGradients</pre>
</li>
</ul>
</li>
</ul>
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="VariationalAutoencoder-org.deeplearning4j.nn.conf.NeuralNetConfiguration-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>VariationalAutoencoder</h4>
<pre>public&nbsp;VariationalAutoencoder(<a href="../../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a>&nbsp;conf)</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="update-org.deeplearning4j.nn.gradient.Gradient-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>update</h4>
<pre>public&nbsp;void&nbsp;update(<a href="../../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;gradient)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#update-org.deeplearning4j.nn.gradient.Gradient-">Model</a></code></span></div>
<div class="block">Update layer weights and biases with gradient change</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#update-org.deeplearning4j.nn.gradient.Gradient-">update</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="update-org.nd4j.linalg.api.ndarray.INDArray-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>update</h4>
<pre>public&nbsp;void&nbsp;update(org.nd4j.linalg.api.ndarray.INDArray&nbsp;gradient,
                   java.lang.String&nbsp;paramType)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#update-org.nd4j.linalg.api.ndarray.INDArray-java.lang.String-">Model</a></code></span></div>
<div class="block">Perform one update  applying the gradient</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#update-org.nd4j.linalg.api.ndarray.INDArray-java.lang.String-">update</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>gradient</code> - the gradient to apply</dd>
</dl>
</li>
</ul>
<a name="score--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>score</h4>
<pre>public&nbsp;double&nbsp;score()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#score--">Model</a></code></span></div>
<div class="block">The score for the model</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#score--">score</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the score for the model</dd>
</dl>
</li>
</ul>
<a name="computeGradientAndScore--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>computeGradientAndScore</h4>
<pre>public&nbsp;void&nbsp;computeGradientAndScore()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#computeGradientAndScore--">Model</a></code></span></div>
<div class="block">Update the score</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#computeGradientAndScore--">computeGradientAndScore</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="accumulateScore-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>accumulateScore</h4>
<pre>public&nbsp;void&nbsp;accumulateScore(double&nbsp;accum)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#accumulateScore-double-">Model</a></code></span></div>
<div class="block">Sets a rolling tally for the score. This is useful for mini batch learning when
 you are accumulating error across a dataset.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#accumulateScore-double-">accumulateScore</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>accum</code> - the amount to accum</dd>
</dl>
</li>
</ul>
<a name="params--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>params</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;params()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#params--">Model</a></code></span></div>
<div class="block">Parameters of the model (if any)</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#params--">params</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the parameters of the model</dd>
</dl>
</li>
</ul>
<a name="numParams--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numParams</h4>
<pre>public&nbsp;int&nbsp;numParams()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#numParams--">Model</a></code></span></div>
<div class="block">the number of parameters for the model</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#numParams--">numParams</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the number of parameters for the model</dd>
</dl>
</li>
</ul>
<a name="numParams-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numParams</h4>
<pre>public&nbsp;int&nbsp;numParams(boolean&nbsp;backwards)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#numParams-boolean-">Model</a></code></span></div>
<div class="block">the number of parameters for the model</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#numParams-boolean-">numParams</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the number of parameters for the model</dd>
</dl>
</li>
</ul>
<a name="setParams-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setParams</h4>
<pre>public&nbsp;void&nbsp;setParams(org.nd4j.linalg.api.ndarray.INDArray&nbsp;params)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#setParams-org.nd4j.linalg.api.ndarray.INDArray-">Model</a></code></span></div>
<div class="block">Set the parameters for this model.
 This expects a linear ndarray which then be unpacked internally
 relative to the expected ordering of the model</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#setParams-org.nd4j.linalg.api.ndarray.INDArray-">setParams</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>params</code> - the parameters for the model</dd>
</dl>
</li>
</ul>
<a name="setParamsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setParamsViewArray</h4>
<pre>public&nbsp;void&nbsp;setParamsViewArray(org.nd4j.linalg.api.ndarray.INDArray&nbsp;params)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#setParamsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">Model</a></code></span></div>
<div class="block">Set the initial parameters array as a view of the full (backprop) network parameters
 NOTE: this is intended to be used internally in MultiLayerNetwork and ComputationGraph, not by users.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#setParamsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">setParamsViewArray</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>params</code> - a 1 x nParams row vector that is a view of the larger (MLN/CG) parameters array</dd>
</dl>
</li>
</ul>
<a name="setBackpropGradientsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setBackpropGradientsViewArray</h4>
<pre>public&nbsp;void&nbsp;setBackpropGradientsViewArray(org.nd4j.linalg.api.ndarray.INDArray&nbsp;gradients)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#setBackpropGradientsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">Model</a></code></span></div>
<div class="block">Set the gradients array as a view of the full (backprop) network parameters
 NOTE: this is intended to be used internally in MultiLayerNetwork and ComputationGraph, not by users.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#setBackpropGradientsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">setBackpropGradientsViewArray</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>gradients</code> - a 1 x nParams row vector that is a view of the larger (MLN/CG) gradients array</dd>
</dl>
</li>
</ul>
<a name="applyLearningRateScoreDecay--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>applyLearningRateScoreDecay</h4>
<pre>public&nbsp;void&nbsp;applyLearningRateScoreDecay()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#applyLearningRateScoreDecay--">Model</a></code></span></div>
<div class="block">Update learningRate using for this model.
 Use the learningRateScoreBasedDecay to adapt the score
 if the Eps termination condition is met</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#applyLearningRateScoreDecay--">applyLearningRateScoreDecay</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="fit-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(org.nd4j.linalg.api.ndarray.INDArray&nbsp;data)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#fit-org.nd4j.linalg.api.ndarray.INDArray-">Model</a></code></span></div>
<div class="block">Fit the model to the given data</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#fit-org.nd4j.linalg.api.ndarray.INDArray-">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - the data to fit the model to</dd>
</dl>
</li>
</ul>
<a name="iterate-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>iterate</h4>
<pre>public&nbsp;void&nbsp;iterate(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#iterate-org.nd4j.linalg.api.ndarray.INDArray-">Model</a></code></span></div>
<div class="block">Run one iteration</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#iterate-org.nd4j.linalg.api.ndarray.INDArray-">iterate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input to iterate on</dd>
</dl>
</li>
</ul>
<a name="gradient--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>gradient</h4>
<pre>public&nbsp;<a href="../../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;gradient()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#gradient--">Model</a></code></span></div>
<div class="block">Calculate a gradient</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#gradient--">gradient</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the gradient for this model</dd>
</dl>
</li>
</ul>
<a name="gradientAndScore--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>gradientAndScore</h4>
<pre>public&nbsp;<a href="../../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;<a href="../../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,java.lang.Double&gt;&nbsp;gradientAndScore()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#gradientAndScore--">Model</a></code></span></div>
<div class="block">Get the gradient and score</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#gradientAndScore--">gradientAndScore</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the gradient and score</dd>
</dl>
</li>
</ul>
<a name="batchSize--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>batchSize</h4>
<pre>public&nbsp;int&nbsp;batchSize()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#batchSize--">Model</a></code></span></div>
<div class="block">The current inputs batch size</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#batchSize--">batchSize</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the current inputs batch size</dd>
</dl>
</li>
</ul>
<a name="conf--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>conf</h4>
<pre>public&nbsp;<a href="../../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a>&nbsp;conf()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#conf--">Model</a></code></span></div>
<div class="block">The configuration for the neural network</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#conf--">conf</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the configuration for the neural network</dd>
</dl>
</li>
</ul>
<a name="setConf-org.deeplearning4j.nn.conf.NeuralNetConfiguration-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setConf</h4>
<pre>public&nbsp;void&nbsp;setConf(<a href="../../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a>&nbsp;conf)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#setConf-org.deeplearning4j.nn.conf.NeuralNetConfiguration-">Model</a></code></span></div>
<div class="block">Setter for the configuration</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#setConf-org.deeplearning4j.nn.conf.NeuralNetConfiguration-">setConf</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="input--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>input</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;input()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#input--">Model</a></code></span></div>
<div class="block">The input/feature matrix for the model</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#input--">input</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the input/feature matrix for the model</dd>
</dl>
</li>
</ul>
<a name="validateInput--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>validateInput</h4>
<pre>public&nbsp;void&nbsp;validateInput()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#validateInput--">Model</a></code></span></div>
<div class="block">Validate the input</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#validateInput--">validateInput</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="getOptimizer--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getOptimizer</h4>
<pre>public&nbsp;<a href="../../../../../org/deeplearning4j/optimize/api/ConvexOptimizer.html" title="interface in org.deeplearning4j.optimize.api">ConvexOptimizer</a>&nbsp;getOptimizer()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#getOptimizer--">Model</a></code></span></div>
<div class="block">Returns this models optimizer</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#getOptimizer--">getOptimizer</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>this models optimizer</dd>
</dl>
</li>
</ul>
<a name="getParam-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getParam</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;getParam(java.lang.String&nbsp;param)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#getParam-java.lang.String-">Model</a></code></span></div>
<div class="block">Get the parameter</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#getParam-java.lang.String-">getParam</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>param</code> - the key of the parameter</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the parameter vector/matrix with that particular key</dd>
</dl>
</li>
</ul>
<a name="initParams--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initParams</h4>
<pre>public&nbsp;void&nbsp;initParams()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#initParams--">Model</a></code></span></div>
<div class="block">Initialize the parameters</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#initParams--">initParams</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="paramTable--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>paramTable</h4>
<pre>public&nbsp;java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;paramTable()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#paramTable--">Model</a></code></span></div>
<div class="block">The param table</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#paramTable--">paramTable</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="paramTable-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>paramTable</h4>
<pre>public&nbsp;java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;paramTable(boolean&nbsp;backpropParamsOnly)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#paramTable-boolean-">Model</a></code></span></div>
<div class="block">Table of parameters by key, for backprop
 For many models (dense layers, etc) - all parameters are backprop parameters</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#paramTable-boolean-">paramTable</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>backpropParamsOnly</code> - If true, return backprop params only. If false: return all params (equivalent to
                           paramsTable())</dd>
</dl>
</li>
</ul>
<a name="setParamTable-java.util.Map-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setParamTable</h4>
<pre>public&nbsp;void&nbsp;setParamTable(java.util.Map&lt;java.lang.String,org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;paramTable)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#setParamTable-java.util.Map-">Model</a></code></span></div>
<div class="block">Setter for the param table</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#setParamTable-java.util.Map-">setParamTable</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="setParam-java.lang.String-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setParam</h4>
<pre>public&nbsp;void&nbsp;setParam(java.lang.String&nbsp;key,
                     org.nd4j.linalg.api.ndarray.INDArray&nbsp;val)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#setParam-java.lang.String-org.nd4j.linalg.api.ndarray.INDArray-">Model</a></code></span></div>
<div class="block">Set the parameter with a new ndarray</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#setParam-java.lang.String-org.nd4j.linalg.api.ndarray.INDArray-">setParam</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>key</code> - the key to se t</dd>
<dd><code>val</code> - the new ndarray</dd>
</dl>
</li>
</ul>
<a name="clear--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clear</h4>
<pre>public&nbsp;void&nbsp;clear()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#clear--">Model</a></code></span></div>
<div class="block">Clear input</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#clear--">clear</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="isPretrainParam-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isPretrainParam</h4>
<pre>public&nbsp;boolean&nbsp;isPretrainParam(java.lang.String&nbsp;param)</pre>
</li>
</ul>
<a name="calcL2-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calcL2</h4>
<pre>public&nbsp;double&nbsp;calcL2(boolean&nbsp;backpropParamsOnly)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#calcL2-boolean-">Layer</a></code></span></div>
<div class="block">Calculate the l2 regularization term<br>
 0.0 if regularization is not used. Or 0.5 * l2Coeff * l2Magnitude otherwise.<br>
 Note that this does not divide by mini-batch size</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#calcL2-boolean-">calcL2</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>backpropParamsOnly</code> - If true: calculate L2 based on backprop params only. If false: calculate
                           based on all params (including pretrain params, if any)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the l2 regularization term for this layer.</dd>
</dl>
</li>
</ul>
<a name="calcL1-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calcL1</h4>
<pre>public&nbsp;double&nbsp;calcL1(boolean&nbsp;backpropParamsOnly)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#calcL1-boolean-">Layer</a></code></span></div>
<div class="block">Calculate the l1 regularization term<br>
 0.0 if regularization is not used. Or l1Coeff * l1Magnitude otherwise.<br>
 Note that this does not divide by mini-batch size</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#calcL1-boolean-">calcL1</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>backpropParamsOnly</code> - If true: calculate L1 based on backprop params only. If false: calculate
                           based on all params (including pretrain params, if any)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the l1 regularization term for this layer.</dd>
</dl>
</li>
</ul>
<a name="type--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>type</h4>
<pre>public&nbsp;<a href="../../../../../org/deeplearning4j/nn/api/Layer.Type.html" title="enum in org.deeplearning4j.nn.api">Layer.Type</a>&nbsp;type()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#type--">Layer</a></code></span></div>
<div class="block">Returns the layer type</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#type--">type</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="error-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>error</h4>
<pre>public&nbsp;<a href="../../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;error(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#error-org.nd4j.linalg.api.ndarray.INDArray-">Layer</a></code></span></div>
<div class="block">Calculate error with respect to the
 current layer.

 This gradient will contain the error signal</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#error-org.nd4j.linalg.api.ndarray.INDArray-">error</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the gradient for the forward layer
              If this is the final layer, it will start
              with the error from the output.
              This is on the user to initialize.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the gradient wrt the parameters
 on the current layer</dd>
</dl>
</li>
</ul>
<a name="derivativeActivation-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>derivativeActivation</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;derivativeActivation(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#derivativeActivation-org.nd4j.linalg.api.ndarray.INDArray-">Layer</a></code></span></div>
<div class="block">Take the derivative of the given input
 based on the activation</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#derivativeActivation-org.nd4j.linalg.api.ndarray.INDArray-">derivativeActivation</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input to take the derivative of</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the derivative of the action</dd>
</dl>
</li>
</ul>
<a name="calcGradient-org.deeplearning4j.nn.gradient.Gradient-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calcGradient</h4>
<pre>public&nbsp;<a href="../../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;calcGradient(<a href="../../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;layerError,
                             org.nd4j.linalg.api.ndarray.INDArray&nbsp;indArray)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#calcGradient-org.deeplearning4j.nn.gradient.Gradient-org.nd4j.linalg.api.ndarray.INDArray-">Layer</a></code></span></div>
<div class="block">Calculate the gradient</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#calcGradient-org.deeplearning4j.nn.gradient.Gradient-org.nd4j.linalg.api.ndarray.INDArray-">calcGradient</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layerError</code> - the layer error</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the gradient</dd>
</dl>
</li>
</ul>
<a name="backpropGradient-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>backpropGradient</h4>
<pre>public&nbsp;<a href="../../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;<a href="../../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,org.nd4j.linalg.api.ndarray.INDArray&gt;&nbsp;backpropGradient(org.nd4j.linalg.api.ndarray.INDArray&nbsp;epsilon)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#backpropGradient-org.nd4j.linalg.api.ndarray.INDArray-">Layer</a></code></span></div>
<div class="block">Calculate the gradient relative to the error in the next layer</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#backpropGradient-org.nd4j.linalg.api.ndarray.INDArray-">backpropGradient</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>epsilon</code> - w^(L+1)*delta^(L+1). Or, equiv: dC/da, i.e., (dC/dz)*(dz/da) = dC/da, where C 
        is cost function a=sigma(z) is activation.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Pair<Gradient,INDArray> where Gradient is gradient for this layer, INDArray is epsilon needed by next
  layer, but before element-wise multiply by sigmaPrime(z). So for standard feed-forward layer, if this layer is
  L, then return.getSecond() == (w^(L)*(delta^(L))^T)^T</dd>
</dl>
</li>
</ul>
<a name="merge-org.deeplearning4j.nn.api.Layer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>merge</h4>
<pre>public&nbsp;void&nbsp;merge(<a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&nbsp;layer,
                  int&nbsp;batchSize)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#merge-org.deeplearning4j.nn.api.Layer-int-">Layer</a></code></span></div>
<div class="block">Parameter averaging</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#merge-org.deeplearning4j.nn.api.Layer-int-">merge</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layer</code> - the layer to merge</dd>
<dd><code>batchSize</code> - the batch size to merge on</dd>
</dl>
</li>
</ul>
<a name="activationMean--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activationMean</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;activationMean()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#activationMean--">Layer</a></code></span></div>
<div class="block">Calculate the mean representation
 for the activation for this layer</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#activationMean--">activationMean</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the activation mean for this layer</dd>
</dl>
</li>
</ul>
<a name="preOutput-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>preOutput</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;preOutput(org.nd4j.linalg.api.ndarray.INDArray&nbsp;x)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#preOutput-org.nd4j.linalg.api.ndarray.INDArray-">Layer</a></code></span></div>
<div class="block">Raw activations</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#preOutput-org.nd4j.linalg.api.ndarray.INDArray-">preOutput</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>x</code> - the input to transform</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the raw activation
 for this layer</dd>
</dl>
</li>
</ul>
<a name="preOutput-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>preOutput</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;preOutput(org.nd4j.linalg.api.ndarray.INDArray&nbsp;x,
                                                      <a href="../../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#preOutput-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">Layer</a></code></span></div>
<div class="block">Raw activations</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#preOutput-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">preOutput</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>x</code> - the input to transform</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the raw activation
 for this layer</dd>
</dl>
</li>
</ul>
<a name="preOutput-org.nd4j.linalg.api.ndarray.INDArray-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>preOutput</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;preOutput(org.nd4j.linalg.api.ndarray.INDArray&nbsp;x,
                                                      boolean&nbsp;training)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#preOutput-org.nd4j.linalg.api.ndarray.INDArray-boolean-">Layer</a></code></span></div>
<div class="block">Raw activations</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#preOutput-org.nd4j.linalg.api.ndarray.INDArray-boolean-">preOutput</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>x</code> - the input to transform</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the raw activation
 for this layer</dd>
</dl>
</li>
</ul>
<a name="preOutput-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>preOutput</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;preOutput(boolean&nbsp;training)</pre>
</li>
</ul>
<a name="activate-org.deeplearning4j.nn.api.Layer.TrainingMode-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;activate(<a href="../../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#activate-org.deeplearning4j.nn.api.Layer.TrainingMode-">Layer</a></code></span></div>
<div class="block">Trigger an activation with the last specified input</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#activate-org.deeplearning4j.nn.api.Layer.TrainingMode-">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>training</code> - training or test mode</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the activation of the last specified input</dd>
</dl>
</li>
</ul>
<a name="activate-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;activate(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
                                                     <a href="../../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#activate-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">Layer</a></code></span></div>
<div class="block">Initialize the layer with the given input
 and return the activation for this layer
 given this input</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#activate-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input to use</dd>
<dd><code>training</code> - train or test mode</dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="activate-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;activate(boolean&nbsp;training)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#activate-boolean-">Layer</a></code></span></div>
<div class="block">Trigger an activation with the last specified input</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#activate-boolean-">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>training</code> - training or test mode</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the activation of the last specified input</dd>
</dl>
</li>
</ul>
<a name="activate-org.nd4j.linalg.api.ndarray.INDArray-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;activate(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input,
                                                     boolean&nbsp;training)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#activate-org.nd4j.linalg.api.ndarray.INDArray-boolean-">Layer</a></code></span></div>
<div class="block">Initialize the layer with the given input
 and return the activation for this layer
 given this input</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#activate-org.nd4j.linalg.api.ndarray.INDArray-boolean-">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input to use</dd>
<dd><code>training</code> - train or test mode</dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="activate--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;activate()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#activate--">Layer</a></code></span></div>
<div class="block">Trigger an activation with the last specified input</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#activate--">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the activation of the last specified input</dd>
</dl>
</li>
</ul>
<a name="activate-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;activate(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#activate-org.nd4j.linalg.api.ndarray.INDArray-">Layer</a></code></span></div>
<div class="block">Initialize the layer with the given input
 and return the activation for this layer
 given this input</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#activate-org.nd4j.linalg.api.ndarray.INDArray-">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input to use</dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="transpose--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>transpose</h4>
<pre>public&nbsp;<a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&nbsp;transpose()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#transpose--">Layer</a></code></span></div>
<div class="block">Return a transposed copy of the weights/bias
 (this means reverse the number of inputs and outputs on the weights)</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#transpose--">transpose</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the transposed layer</dd>
</dl>
</li>
</ul>
<a name="clone--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clone</h4>
<pre>public&nbsp;<a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&nbsp;clone()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#clone--">Layer</a></code></span></div>
<div class="block">Clone the layer</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#clone--">clone</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="overrideSpecifyLabel">Overrides:</span></dt>
<dd><code>clone</code>&nbsp;in class&nbsp;<code>java.lang.Object</code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="getListeners--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getListeners</h4>
<pre>public&nbsp;java.util.Collection&lt;<a href="../../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>&gt;&nbsp;getListeners()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#getListeners--">Layer</a></code></span></div>
<div class="block">Get the iteration listeners for this layer.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#getListeners--">getListeners</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="setListeners-org.deeplearning4j.optimize.api.IterationListener...-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setListeners</h4>
<pre>public&nbsp;void&nbsp;setListeners(<a href="../../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>...&nbsp;listeners)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#setListeners-org.deeplearning4j.optimize.api.IterationListener...-">Layer</a></code></span></div>
<div class="block">Set the iteration listeners for this layer.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#setListeners-org.deeplearning4j.optimize.api.IterationListener...-">setListeners</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#setListeners-org.deeplearning4j.optimize.api.IterationListener...-">setListeners</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="setListeners-java.util.Collection-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setListeners</h4>
<pre>public&nbsp;void&nbsp;setListeners(java.util.Collection&lt;<a href="../../../../../org/deeplearning4j/optimize/api/IterationListener.html" title="interface in org.deeplearning4j.optimize.api">IterationListener</a>&gt;&nbsp;listeners)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#setListeners-java.util.Collection-">Layer</a></code></span></div>
<div class="block">Set the iteration listeners for this layer.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#setListeners-java.util.Collection-">setListeners</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#setListeners-java.util.Collection-">setListeners</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="setIndex-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setIndex</h4>
<pre>public&nbsp;void&nbsp;setIndex(int&nbsp;index)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#setIndex-int-">Layer</a></code></span></div>
<div class="block">Set the layer index.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#setIndex-int-">setIndex</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="getIndex--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getIndex</h4>
<pre>public&nbsp;int&nbsp;getIndex()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#getIndex--">Layer</a></code></span></div>
<div class="block">Get the layer index.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#getIndex--">getIndex</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="setInput-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setInput</h4>
<pre>public&nbsp;void&nbsp;setInput(org.nd4j.linalg.api.ndarray.INDArray&nbsp;input)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#setInput-org.nd4j.linalg.api.ndarray.INDArray-">Layer</a></code></span></div>
<div class="block">Get the layer input.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#setInput-org.nd4j.linalg.api.ndarray.INDArray-">setInput</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="setInputMiniBatchSize-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setInputMiniBatchSize</h4>
<pre>public&nbsp;void&nbsp;setInputMiniBatchSize(int&nbsp;size)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#setInputMiniBatchSize-int-">Layer</a></code></span></div>
<div class="block">Set current/last input mini-batch size.<br>
 Used for score and gradient calculations. Mini batch size may be different from
 getInput().size(0) due to reshaping operations - for example, when using RNNs with
 DenseLayer and OutputLayer. Called automatically during forward pass.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#setInputMiniBatchSize-int-">setInputMiniBatchSize</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="getInputMiniBatchSize--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getInputMiniBatchSize</h4>
<pre>public&nbsp;int&nbsp;getInputMiniBatchSize()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#getInputMiniBatchSize--">Layer</a></code></span></div>
<div class="block">Get current/last input mini-batch size, as set by setInputMiniBatchSize(int)</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#getInputMiniBatchSize--">getInputMiniBatchSize</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#setInputMiniBatchSize-int-"><code>Layer.setInputMiniBatchSize(int)</code></a></dd>
</dl>
</li>
</ul>
<a name="setMaskArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setMaskArray</h4>
<pre>public&nbsp;void&nbsp;setMaskArray(org.nd4j.linalg.api.ndarray.INDArray&nbsp;maskArray)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#setMaskArray-org.nd4j.linalg.api.ndarray.INDArray-">Layer</a></code></span></div>
<div class="block">Set the mask array. Note: In general, <a href="../../../../../org/deeplearning4j/nn/api/Layer.html#feedForwardMaskArray-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.MaskState-int-"><code>Layer.feedForwardMaskArray(INDArray, MaskState, int)</code></a> should be used in
 preference to this.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#setMaskArray-org.nd4j.linalg.api.ndarray.INDArray-">setMaskArray</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>maskArray</code> - Mask array to set</dd>
</dl>
</li>
</ul>
<a name="getMaskArray--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getMaskArray</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;getMaskArray()</pre>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#getMaskArray--">getMaskArray</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="isPretrainLayer--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isPretrainLayer</h4>
<pre>public&nbsp;boolean&nbsp;isPretrainLayer()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#isPretrainLayer--">Layer</a></code></span></div>
<div class="block">Returns true if the layer can be trained in an unsupervised/pretrain manner (VAE, RBMs etc)</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#isPretrainLayer--">isPretrainLayer</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>true if the layer can be pretrained (using fit(INDArray), false otherwise</dd>
</dl>
</li>
</ul>
<a name="feedForwardMaskArray-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.MaskState-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForwardMaskArray</h4>
<pre>public&nbsp;<a href="../../../../../org/deeplearning4j/berkeley/Pair.html" title="class in org.deeplearning4j.berkeley">Pair</a>&lt;org.nd4j.linalg.api.ndarray.INDArray,<a href="../../../../../org/deeplearning4j/nn/api/MaskState.html" title="enum in org.deeplearning4j.nn.api">MaskState</a>&gt;&nbsp;feedForwardMaskArray(org.nd4j.linalg.api.ndarray.INDArray&nbsp;maskArray,
                                                                                 <a href="../../../../../org/deeplearning4j/nn/api/MaskState.html" title="enum in org.deeplearning4j.nn.api">MaskState</a>&nbsp;currentMaskState,
                                                                                 int&nbsp;minibatchSize)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#feedForwardMaskArray-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.MaskState-int-">Layer</a></code></span></div>
<div class="block">Feed forward the input mask array, setting in in the layer as appropriate. This allows different layers to
 handle masks differently - for example, bidirectional RNNs and normal RNNs operate differently with masks (the
 former sets activations to 0 outside of the data present region (and keeps the mask active for future layers like
 dense layers), whereas normal RNNs don't zero out the activations/errors )instead relying on backpropagated error
 arrays to handle the variable length case.<br>
 This is also used for example for networks that contain global pooling layers, arbitrary preprocessors, etc.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html#feedForwardMaskArray-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.MaskState-int-">feedForwardMaskArray</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>maskArray</code> - Mask array to set</dd>
<dd><code>currentMaskState</code> - Current state of the mask - see <a href="../../../../../org/deeplearning4j/nn/api/MaskState.html" title="enum in org.deeplearning4j.nn.api"><code>MaskState</code></a></dd>
<dd><code>minibatchSize</code> - Current minibatch size. Needs to be known as it cannot always be inferred from the activations
                         array due to reshaping (such as a DenseLayer within a recurrent neural network)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>New mask array after this layer, along with the new mask state.</dd>
</dl>
</li>
</ul>
<a name="fit--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#fit--">Model</a></code></span></div>
<div class="block">All models have a fit method</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../../org/deeplearning4j/nn/api/Model.html#fit--">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="reconstructionProbability-org.nd4j.linalg.api.ndarray.INDArray-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reconstructionProbability</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;reconstructionProbability(org.nd4j.linalg.api.ndarray.INDArray&nbsp;data,
                                                                      int&nbsp;numSamples)</pre>
<div class="block">Calculate the reconstruction probability, as described in An & Cho, 2015 - "Variational Autoencoder based
 Anomaly Detection using Reconstruction Probability" (Algorithm 4)<br>
 The authors describe it as follows: "This is essentially the probability of the data being generated from a given
 latent variable drawn from the approximate posterior distribution."<br>
 <br>
 Specifically, for each example x in the input, calculate p(x). Note however that p(x) is a stochastic (Monte-Carlo)
 estimate of the true p(x), based on the specified number of samples. More samples will produce a more accurate
 (lower variance) estimate of the true p(x) for the current model parameters.<br>
 <br>
 Internally uses <a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#reconstructionLogProbability-org.nd4j.linalg.api.ndarray.INDArray-int-"><code>reconstructionLogProbability(INDArray, int)</code></a> for the actual implementation.
 That method may be more numerically stable in some cases.<br>
 <br>
 The returned array is a column vector of reconstruction probabilities, for each example. Thus, reconstruction probabilities
 can (and should, for efficiency) be calculated in a batched manner.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - The data to calculate the reconstruction probability for</dd>
<dd><code>numSamples</code> - Number of samples with which to base the reconstruction probability on.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Column vector of reconstruction probabilities for each example (shape: [numExamples,1])</dd>
</dl>
</li>
</ul>
<a name="reconstructionLogProbability-org.nd4j.linalg.api.ndarray.INDArray-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reconstructionLogProbability</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;reconstructionLogProbability(org.nd4j.linalg.api.ndarray.INDArray&nbsp;data,
                                                                         int&nbsp;numSamples)</pre>
<div class="block">Return the log reconstruction probability given the specified number of samples.<br>
 See <a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#reconstructionLogProbability-org.nd4j.linalg.api.ndarray.INDArray-int-"><code>reconstructionLogProbability(INDArray, int)</code></a> for more details</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - The data to calculate the log reconstruction probability</dd>
<dd><code>numSamples</code> - Number of samples with which to base the reconstruction probability on.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Column vector of reconstruction log probabilities for each example (shape: [numExamples,1])</dd>
</dl>
</li>
</ul>
<a name="generateAtMeanGivenZ-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>generateAtMeanGivenZ</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;generateAtMeanGivenZ(org.nd4j.linalg.api.ndarray.INDArray&nbsp;latentSpaceValues)</pre>
<div class="block">Given a specified values for the latent space as input (latent space being z in p(z|data)), generate output
 from P(x|z), where x = E[P(x|z)]<br>
 i.e., return the mean value for the distribution P(x|z)</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>latentSpaceValues</code> - Values for the latent space. size(1) must equal nOut configuration parameter</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Sample of data: E[P(x|z)]</dd>
</dl>
</li>
</ul>
<a name="generateRandomGivenZ-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>generateRandomGivenZ</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;generateRandomGivenZ(org.nd4j.linalg.api.ndarray.INDArray&nbsp;latentSpaceValues)</pre>
<div class="block">Given a specified values for the latent space as input (latent space being z in p(z|data)), randomly generate output
 x, where x ~ P(x|z)</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>latentSpaceValues</code> - Values for the latent space. size(1) must equal nOut configuration parameter</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Sample of data: x ~ P(x|z)</dd>
</dl>
</li>
</ul>
<a name="hasLossFunction--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>hasLossFunction</h4>
<pre>public&nbsp;boolean&nbsp;hasLossFunction()</pre>
<div class="block">Does the reconstruction distribution have a loss function (such as mean squared error) or is it a standard
 probabilistic reconstruction distribution?</div>
</li>
</ul>
<a name="reconstructionError-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>reconstructionError</h4>
<pre>public&nbsp;org.nd4j.linalg.api.ndarray.INDArray&nbsp;reconstructionError(org.nd4j.linalg.api.ndarray.INDArray&nbsp;data)</pre>
<div class="block">Return the reconstruction error for this variational autoencoder.<br>
 <b>NOTE (important):</b> This method is used ONLY for VAEs that have a standard neural network loss function (i.e.,
 an <code>ILossFunction</code> instance such as mean squared error) instead of using a
 probabilistic reconstruction distribution P(x|z) for the reconstructions (as presented in the VAE architecture by
 Kingma and Welling).<br>
 You can check if the VAE has a loss function using <a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#hasLossFunction--"><code>hasLossFunction()</code></a><br>
 Consequently, the reconstruction error is a simple deterministic function (no Monte-Carlo sampling is required,
 unlike <a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#reconstructionProbability-org.nd4j.linalg.api.ndarray.INDArray-int-"><code>reconstructionProbability(INDArray, int)</code></a> and <a href="../../../../../org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html#reconstructionLogProbability-org.nd4j.linalg.api.ndarray.INDArray-int-"><code>reconstructionLogProbability(INDArray, int)</code></a>)</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - The data to calculate the reconstruction error on</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Column vector of reconstruction errors for each example (shape: [numExamples,1])</dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev&nbsp;Class</li>
<li>Next&nbsp;Class</li>
</ul>
<ul class="navList">
<li><a href="../../../../../index.html?org/deeplearning4j/nn/layers/variational/VariationalAutoencoder.html" target="_top">Frames</a></li>
<li><a href="VariationalAutoencoder.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field.summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field.detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
